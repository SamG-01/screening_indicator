{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "import pynucastro as pyna\n",
    "\n",
    "import chugunov_indicator as chug\n",
    "\n",
    "fixed_rng = np.random.default_rng(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reduced our original task to a binary classification problem of the form\n",
    "$$\n",
    "    s = s(y_0; \\bar{A}, \\overline{Z^2}; Z_1, Z_2) \\in \\{0, 1\\}, \\quad y_0 := 3 \\log_{10} T - \\log_{10} D.\n",
    "$$\n",
    "To solve this problem without manual fitting, we could also try training a neural network in `keras` that predicts when screening can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"size\": 3*10**5, \"rng\": fixed_rng}\n",
    "\n",
    "train = chug.ScreeningFactorData(**kwargs)\n",
    "validate = chug.ScreeningFactorData(**kwargs)\n",
    "test = chug.ScreeningFactorData(**kwargs)\n",
    "\n",
    "network = chug.ScreeningFactorNetwork(train, validate, test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.class_weight = {0: 64983, 1: 35017*2}\n",
    "network.compile(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "147/147 - 4s - 29ms/step - fn: 16226.0000 - fp: 14267.0000 - loss: 23067.8379 - precision: 0.8612 - recall: 0.8451 - tn: 181004.0000 - tp: 88503.0000 - val_fn: 4684.0000 - val_fp: 6376.0000 - val_loss: 0.1046 - val_precision: 0.9402 - val_recall: 0.9554 - val_tn: 188621.0000 - val_tp: 100319.0000\n",
      "Epoch 2/500\n",
      "147/147 - 2s - 11ms/step - fn: 3893.0000 - fp: 6103.0000 - loss: 5712.7471 - precision: 0.9429 - recall: 0.9628 - tn: 189168.0000 - tp: 100836.0000 - val_fn: 3215.0000 - val_fp: 4057.0000 - val_loss: 0.0613 - val_precision: 0.9617 - val_recall: 0.9694 - val_tn: 190940.0000 - val_tp: 101788.0000\n",
      "Epoch 3/500\n",
      "147/147 - 2s - 11ms/step - fn: 2689.0000 - fp: 4063.0000 - loss: 3789.4741 - precision: 0.9617 - recall: 0.9743 - tn: 191208.0000 - tp: 102040.0000 - val_fn: 2271.0000 - val_fp: 2642.0000 - val_loss: 0.0434 - val_precision: 0.9749 - val_recall: 0.9784 - val_tn: 192355.0000 - val_tp: 102732.0000\n",
      "Epoch 4/500\n",
      "147/147 - 2s - 12ms/step - fn: 2172.0000 - fp: 2921.0000 - loss: 2871.2119 - precision: 0.9723 - recall: 0.9793 - tn: 192350.0000 - tp: 102557.0000 - val_fn: 1966.0000 - val_fp: 1783.0000 - val_loss: 0.0343 - val_precision: 0.9830 - val_recall: 0.9813 - val_tn: 193214.0000 - val_tp: 103037.0000\n",
      "Epoch 5/500\n",
      "147/147 - 2s - 11ms/step - fn: 1888.0000 - fp: 2296.0000 - loss: 2378.1484 - precision: 0.9782 - recall: 0.9820 - tn: 192975.0000 - tp: 102841.0000 - val_fn: 1660.0000 - val_fp: 1522.0000 - val_loss: 0.0294 - val_precision: 0.9855 - val_recall: 0.9842 - val_tn: 193475.0000 - val_tp: 103343.0000\n",
      "Epoch 6/500\n",
      "147/147 - 2s - 11ms/step - fn: 1745.0000 - fp: 2012.0000 - loss: 2093.7139 - precision: 0.9808 - recall: 0.9833 - tn: 193259.0000 - tp: 102984.0000 - val_fn: 1794.0000 - val_fp: 1167.0000 - val_loss: 0.0266 - val_precision: 0.9888 - val_recall: 0.9829 - val_tn: 193830.0000 - val_tp: 103209.0000\n",
      "Epoch 7/500\n",
      "147/147 - 2s - 10ms/step - fn: 1561.0000 - fp: 1810.0000 - loss: 1889.1116 - precision: 0.9828 - recall: 0.9851 - tn: 193461.0000 - tp: 103168.0000 - val_fn: 1638.0000 - val_fp: 1117.0000 - val_loss: 0.0244 - val_precision: 0.9893 - val_recall: 0.9844 - val_tn: 193880.0000 - val_tp: 103365.0000\n",
      "Epoch 8/500\n",
      "147/147 - 2s - 11ms/step - fn: 1481.0000 - fp: 1650.0000 - loss: 1748.6134 - precision: 0.9843 - recall: 0.9859 - tn: 193621.0000 - tp: 103248.0000 - val_fn: 1577.0000 - val_fp: 997.0000 - val_loss: 0.0227 - val_precision: 0.9905 - val_recall: 0.9850 - val_tn: 194000.0000 - val_tp: 103426.0000\n",
      "Epoch 9/500\n",
      "147/147 - 2s - 11ms/step - fn: 1413.0000 - fp: 1548.0000 - loss: 1634.4049 - precision: 0.9852 - recall: 0.9865 - tn: 193723.0000 - tp: 103316.0000 - val_fn: 1318.0000 - val_fp: 1084.0000 - val_loss: 0.0211 - val_precision: 0.9897 - val_recall: 0.9874 - val_tn: 193913.0000 - val_tp: 103685.0000\n",
      "Epoch 10/500\n",
      "147/147 - 2s - 10ms/step - fn: 1315.0000 - fp: 1433.0000 - loss: 1529.7966 - precision: 0.9863 - recall: 0.9874 - tn: 193838.0000 - tp: 103414.0000 - val_fn: 1391.0000 - val_fp: 903.0000 - val_loss: 0.0201 - val_precision: 0.9914 - val_recall: 0.9868 - val_tn: 194094.0000 - val_tp: 103612.0000\n",
      "Epoch 11/500\n",
      "147/147 - 2s - 11ms/step - fn: 1262.0000 - fp: 1339.0000 - loss: 1445.6080 - precision: 0.9872 - recall: 0.9879 - tn: 193932.0000 - tp: 103467.0000 - val_fn: 1264.0000 - val_fp: 926.0000 - val_loss: 0.0189 - val_precision: 0.9912 - val_recall: 0.9880 - val_tn: 194071.0000 - val_tp: 103739.0000\n",
      "Epoch 12/500\n",
      "147/147 - 2s - 11ms/step - fn: 1117.0000 - fp: 1249.0000 - loss: 1342.9846 - precision: 0.9881 - recall: 0.9893 - tn: 194022.0000 - tp: 103612.0000 - val_fn: 1269.0000 - val_fp: 810.0000 - val_loss: 0.0180 - val_precision: 0.9923 - val_recall: 0.9879 - val_tn: 194187.0000 - val_tp: 103734.0000\n",
      "Epoch 13/500\n",
      "147/147 - 2s - 11ms/step - fn: 1129.0000 - fp: 1208.0000 - loss: 1276.3837 - precision: 0.9885 - recall: 0.9892 - tn: 194063.0000 - tp: 103600.0000 - val_fn: 1216.0000 - val_fp: 765.0000 - val_loss: 0.0171 - val_precision: 0.9927 - val_recall: 0.9884 - val_tn: 194232.0000 - val_tp: 103787.0000\n",
      "Epoch 14/500\n",
      "147/147 - 2s - 11ms/step - fn: 1036.0000 - fp: 1116.0000 - loss: 1210.9453 - precision: 0.9894 - recall: 0.9901 - tn: 194155.0000 - tp: 103693.0000 - val_fn: 1090.0000 - val_fp: 782.0000 - val_loss: 0.0161 - val_precision: 0.9925 - val_recall: 0.9896 - val_tn: 194215.0000 - val_tp: 103913.0000\n",
      "Epoch 15/500\n",
      "147/147 - 2s - 11ms/step - fn: 977.0000 - fp: 1079.0000 - loss: 1155.2506 - precision: 0.9897 - recall: 0.9907 - tn: 194192.0000 - tp: 103752.0000 - val_fn: 1080.0000 - val_fp: 694.0000 - val_loss: 0.0155 - val_precision: 0.9934 - val_recall: 0.9897 - val_tn: 194303.0000 - val_tp: 103923.0000\n",
      "Epoch 16/500\n",
      "147/147 - 2s - 11ms/step - fn: 946.0000 - fp: 993.0000 - loss: 1099.6254 - precision: 0.9905 - recall: 0.9910 - tn: 194278.0000 - tp: 103783.0000 - val_fn: 1233.0000 - val_fp: 547.0000 - val_loss: 0.0151 - val_precision: 0.9948 - val_recall: 0.9883 - val_tn: 194450.0000 - val_tp: 103770.0000\n",
      "Epoch 17/500\n",
      "147/147 - 2s - 11ms/step - fn: 896.0000 - fp: 967.0000 - loss: 1055.8500 - precision: 0.9908 - recall: 0.9914 - tn: 194304.0000 - tp: 103833.0000 - val_fn: 1022.0000 - val_fp: 633.0000 - val_loss: 0.0142 - val_precision: 0.9939 - val_recall: 0.9903 - val_tn: 194364.0000 - val_tp: 103981.0000\n",
      "Epoch 18/500\n",
      "147/147 - 2s - 11ms/step - fn: 849.0000 - fp: 931.0000 - loss: 1005.4213 - precision: 0.9911 - recall: 0.9919 - tn: 194340.0000 - tp: 103880.0000 - val_fn: 936.0000 - val_fp: 633.0000 - val_loss: 0.0136 - val_precision: 0.9940 - val_recall: 0.9911 - val_tn: 194364.0000 - val_tp: 104067.0000\n",
      "Epoch 19/500\n",
      "147/147 - 2s - 11ms/step - fn: 790.0000 - fp: 904.0000 - loss: 954.6050 - precision: 0.9914 - recall: 0.9925 - tn: 194367.0000 - tp: 103939.0000 - val_fn: 917.0000 - val_fp: 595.0000 - val_loss: 0.0130 - val_precision: 0.9943 - val_recall: 0.9913 - val_tn: 194402.0000 - val_tp: 104086.0000\n",
      "Epoch 20/500\n",
      "147/147 - 2s - 11ms/step - fn: 744.0000 - fp: 852.0000 - loss: 912.4226 - precision: 0.9919 - recall: 0.9929 - tn: 194419.0000 - tp: 103985.0000 - val_fn: 919.0000 - val_fp: 532.0000 - val_loss: 0.0126 - val_precision: 0.9949 - val_recall: 0.9912 - val_tn: 194465.0000 - val_tp: 104084.0000\n",
      "Epoch 21/500\n",
      "147/147 - 2s - 11ms/step - fn: 711.0000 - fp: 791.0000 - loss: 874.7817 - precision: 0.9925 - recall: 0.9932 - tn: 194480.0000 - tp: 104018.0000 - val_fn: 850.0000 - val_fp: 533.0000 - val_loss: 0.0121 - val_precision: 0.9949 - val_recall: 0.9919 - val_tn: 194464.0000 - val_tp: 104153.0000\n",
      "Epoch 22/500\n",
      "147/147 - 2s - 11ms/step - fn: 691.0000 - fp: 767.0000 - loss: 846.5944 - precision: 0.9927 - recall: 0.9934 - tn: 194504.0000 - tp: 104038.0000 - val_fn: 840.0000 - val_fp: 543.0000 - val_loss: 0.0118 - val_precision: 0.9948 - val_recall: 0.9920 - val_tn: 194454.0000 - val_tp: 104163.0000\n",
      "Epoch 23/500\n",
      "147/147 - 2s - 11ms/step - fn: 666.0000 - fp: 735.0000 - loss: 807.9771 - precision: 0.9930 - recall: 0.9936 - tn: 194536.0000 - tp: 104063.0000 - val_fn: 778.0000 - val_fp: 544.0000 - val_loss: 0.0114 - val_precision: 0.9948 - val_recall: 0.9926 - val_tn: 194453.0000 - val_tp: 104225.0000\n",
      "Epoch 24/500\n",
      "147/147 - 2s - 11ms/step - fn: 653.0000 - fp: 715.0000 - loss: 784.2994 - precision: 0.9932 - recall: 0.9938 - tn: 194556.0000 - tp: 104076.0000 - val_fn: 826.0000 - val_fp: 415.0000 - val_loss: 0.0110 - val_precision: 0.9960 - val_recall: 0.9921 - val_tn: 194582.0000 - val_tp: 104177.0000\n",
      "Epoch 25/500\n",
      "147/147 - 2s - 11ms/step - fn: 618.0000 - fp: 701.0000 - loss: 754.6071 - precision: 0.9933 - recall: 0.9941 - tn: 194570.0000 - tp: 104111.0000 - val_fn: 800.0000 - val_fp: 475.0000 - val_loss: 0.0108 - val_precision: 0.9955 - val_recall: 0.9924 - val_tn: 194522.0000 - val_tp: 104203.0000\n",
      "Epoch 26/500\n",
      "147/147 - 2s - 13ms/step - fn: 598.0000 - fp: 669.0000 - loss: 724.3141 - precision: 0.9936 - recall: 0.9943 - tn: 194602.0000 - tp: 104131.0000 - val_fn: 769.0000 - val_fp: 437.0000 - val_loss: 0.0104 - val_precision: 0.9958 - val_recall: 0.9927 - val_tn: 194560.0000 - val_tp: 104234.0000\n",
      "Epoch 27/500\n",
      "147/147 - 2s - 12ms/step - fn: 578.0000 - fp: 640.0000 - loss: 711.3857 - precision: 0.9939 - recall: 0.9945 - tn: 194631.0000 - tp: 104151.0000 - val_fn: 690.0000 - val_fp: 452.0000 - val_loss: 0.0100 - val_precision: 0.9957 - val_recall: 0.9934 - val_tn: 194545.0000 - val_tp: 104313.0000\n",
      "Epoch 28/500\n",
      "147/147 - 2s - 14ms/step - fn: 576.0000 - fp: 655.0000 - loss: 693.6240 - precision: 0.9938 - recall: 0.9945 - tn: 194616.0000 - tp: 104153.0000 - val_fn: 837.0000 - val_fp: 383.0000 - val_loss: 0.0101 - val_precision: 0.9963 - val_recall: 0.9920 - val_tn: 194614.0000 - val_tp: 104166.0000\n",
      "Epoch 29/500\n",
      "147/147 - 2s - 16ms/step - fn: 572.0000 - fp: 596.0000 - loss: 661.4510 - precision: 0.9943 - recall: 0.9945 - tn: 194675.0000 - tp: 104157.0000 - val_fn: 790.0000 - val_fp: 368.0000 - val_loss: 0.0097 - val_precision: 0.9965 - val_recall: 0.9925 - val_tn: 194629.0000 - val_tp: 104213.0000\n",
      "Epoch 30/500\n",
      "147/147 - 2s - 16ms/step - fn: 526.0000 - fp: 578.0000 - loss: 643.6485 - precision: 0.9945 - recall: 0.9950 - tn: 194693.0000 - tp: 104203.0000 - val_fn: 711.0000 - val_fp: 391.0000 - val_loss: 0.0093 - val_precision: 0.9963 - val_recall: 0.9932 - val_tn: 194606.0000 - val_tp: 104292.0000\n",
      "Epoch 31/500\n",
      "147/147 - 2s - 16ms/step - fn: 501.0000 - fp: 545.0000 - loss: 617.8976 - precision: 0.9948 - recall: 0.9952 - tn: 194726.0000 - tp: 104228.0000 - val_fn: 752.0000 - val_fp: 350.0000 - val_loss: 0.0092 - val_precision: 0.9967 - val_recall: 0.9928 - val_tn: 194647.0000 - val_tp: 104251.0000\n",
      "Epoch 32/500\n",
      "147/147 - 2s - 17ms/step - fn: 479.0000 - fp: 559.0000 - loss: 615.0971 - precision: 0.9947 - recall: 0.9954 - tn: 194712.0000 - tp: 104250.0000 - val_fn: 688.0000 - val_fp: 370.0000 - val_loss: 0.0089 - val_precision: 0.9965 - val_recall: 0.9934 - val_tn: 194627.0000 - val_tp: 104315.0000\n",
      "Epoch 33/500\n",
      "147/147 - 2s - 17ms/step - fn: 481.0000 - fp: 548.0000 - loss: 590.8361 - precision: 0.9948 - recall: 0.9954 - tn: 194723.0000 - tp: 104248.0000 - val_fn: 653.0000 - val_fp: 356.0000 - val_loss: 0.0086 - val_precision: 0.9966 - val_recall: 0.9938 - val_tn: 194641.0000 - val_tp: 104350.0000\n",
      "Epoch 34/500\n",
      "147/147 - 2s - 17ms/step - fn: 457.0000 - fp: 536.0000 - loss: 583.7772 - precision: 0.9949 - recall: 0.9956 - tn: 194735.0000 - tp: 104272.0000 - val_fn: 754.0000 - val_fp: 339.0000 - val_loss: 0.0088 - val_precision: 0.9968 - val_recall: 0.9928 - val_tn: 194658.0000 - val_tp: 104249.0000\n",
      "Epoch 35/500\n",
      "147/147 - 2s - 17ms/step - fn: 471.0000 - fp: 502.0000 - loss: 562.0800 - precision: 0.9952 - recall: 0.9955 - tn: 194769.0000 - tp: 104258.0000 - val_fn: 562.0000 - val_fp: 409.0000 - val_loss: 0.0082 - val_precision: 0.9961 - val_recall: 0.9946 - val_tn: 194588.0000 - val_tp: 104441.0000\n",
      "Epoch 36/500\n",
      "147/147 - 2s - 16ms/step - fn: 469.0000 - fp: 509.0000 - loss: 556.4587 - precision: 0.9951 - recall: 0.9955 - tn: 194762.0000 - tp: 104260.0000 - val_fn: 590.0000 - val_fp: 387.0000 - val_loss: 0.0082 - val_precision: 0.9963 - val_recall: 0.9944 - val_tn: 194610.0000 - val_tp: 104413.0000\n",
      "Epoch 37/500\n",
      "147/147 - 2s - 17ms/step - fn: 438.0000 - fp: 513.0000 - loss: 546.9698 - precision: 0.9951 - recall: 0.9958 - tn: 194758.0000 - tp: 104291.0000 - val_fn: 728.0000 - val_fp: 314.0000 - val_loss: 0.0083 - val_precision: 0.9970 - val_recall: 0.9931 - val_tn: 194683.0000 - val_tp: 104275.0000\n",
      "Epoch 38/500\n",
      "147/147 - 2s - 17ms/step - fn: 415.0000 - fp: 461.0000 - loss: 523.0649 - precision: 0.9956 - recall: 0.9960 - tn: 194810.0000 - tp: 104314.0000 - val_fn: 687.0000 - val_fp: 323.0000 - val_loss: 0.0081 - val_precision: 0.9969 - val_recall: 0.9935 - val_tn: 194674.0000 - val_tp: 104316.0000\n",
      "Epoch 39/500\n",
      "147/147 - 2s - 16ms/step - fn: 429.0000 - fp: 481.0000 - loss: 511.6891 - precision: 0.9954 - recall: 0.9959 - tn: 194790.0000 - tp: 104300.0000 - val_fn: 556.0000 - val_fp: 363.0000 - val_loss: 0.0076 - val_precision: 0.9965 - val_recall: 0.9947 - val_tn: 194634.0000 - val_tp: 104447.0000\n",
      "Epoch 40/500\n",
      "147/147 - 2s - 17ms/step - fn: 430.0000 - fp: 472.0000 - loss: 507.0989 - precision: 0.9955 - recall: 0.9959 - tn: 194799.0000 - tp: 104299.0000 - val_fn: 595.0000 - val_fp: 321.0000 - val_loss: 0.0076 - val_precision: 0.9969 - val_recall: 0.9943 - val_tn: 194676.0000 - val_tp: 104408.0000\n",
      "Epoch 41/500\n",
      "147/147 - 2s - 17ms/step - fn: 392.0000 - fp: 450.0000 - loss: 490.0391 - precision: 0.9957 - recall: 0.9963 - tn: 194821.0000 - tp: 104337.0000 - val_fn: 652.0000 - val_fp: 339.0000 - val_loss: 0.0079 - val_precision: 0.9968 - val_recall: 0.9938 - val_tn: 194658.0000 - val_tp: 104351.0000\n",
      "Epoch 42/500\n",
      "147/147 - 2s - 17ms/step - fn: 389.0000 - fp: 463.0000 - loss: 487.2096 - precision: 0.9956 - recall: 0.9963 - tn: 194808.0000 - tp: 104340.0000 - val_fn: 506.0000 - val_fp: 327.0000 - val_loss: 0.0072 - val_precision: 0.9969 - val_recall: 0.9952 - val_tn: 194670.0000 - val_tp: 104497.0000\n",
      "Epoch 43/500\n",
      "147/147 - 2s - 17ms/step - fn: 401.0000 - fp: 452.0000 - loss: 480.3997 - precision: 0.9957 - recall: 0.9962 - tn: 194819.0000 - tp: 104328.0000 - val_fn: 602.0000 - val_fp: 300.0000 - val_loss: 0.0073 - val_precision: 0.9971 - val_recall: 0.9943 - val_tn: 194697.0000 - val_tp: 104401.0000\n",
      "Epoch 44/500\n",
      "147/147 - 2s - 16ms/step - fn: 389.0000 - fp: 448.0000 - loss: 472.1376 - precision: 0.9957 - recall: 0.9963 - tn: 194823.0000 - tp: 104340.0000 - val_fn: 523.0000 - val_fp: 336.0000 - val_loss: 0.0070 - val_precision: 0.9968 - val_recall: 0.9950 - val_tn: 194661.0000 - val_tp: 104480.0000\n",
      "Epoch 45/500\n",
      "147/147 - 2s - 17ms/step - fn: 358.0000 - fp: 424.0000 - loss: 452.7794 - precision: 0.9960 - recall: 0.9966 - tn: 194847.0000 - tp: 104371.0000 - val_fn: 587.0000 - val_fp: 325.0000 - val_loss: 0.0072 - val_precision: 0.9969 - val_recall: 0.9944 - val_tn: 194672.0000 - val_tp: 104416.0000\n",
      "Epoch 46/500\n",
      "147/147 - 2s - 17ms/step - fn: 373.0000 - fp: 429.0000 - loss: 454.9855 - precision: 0.9959 - recall: 0.9964 - tn: 194842.0000 - tp: 104356.0000 - val_fn: 587.0000 - val_fp: 277.0000 - val_loss: 0.0069 - val_precision: 0.9974 - val_recall: 0.9944 - val_tn: 194720.0000 - val_tp: 104416.0000\n",
      "Epoch 47/500\n",
      "147/147 - 3s - 17ms/step - fn: 357.0000 - fp: 418.0000 - loss: 451.2365 - precision: 0.9960 - recall: 0.9966 - tn: 194853.0000 - tp: 104372.0000 - val_fn: 611.0000 - val_fp: 252.0000 - val_loss: 0.0069 - val_precision: 0.9976 - val_recall: 0.9942 - val_tn: 194745.0000 - val_tp: 104392.0000\n",
      "Epoch 48/500\n",
      "147/147 - 2s - 17ms/step - fn: 353.0000 - fp: 419.0000 - loss: 432.2338 - precision: 0.9960 - recall: 0.9966 - tn: 194852.0000 - tp: 104376.0000 - val_fn: 382.0000 - val_fp: 363.0000 - val_loss: 0.0063 - val_precision: 0.9965 - val_recall: 0.9964 - val_tn: 194634.0000 - val_tp: 104621.0000\n",
      "Epoch 49/500\n",
      "147/147 - 2s - 17ms/step - fn: 351.0000 - fp: 398.0000 - loss: 431.1422 - precision: 0.9962 - recall: 0.9966 - tn: 194873.0000 - tp: 104378.0000 - val_fn: 571.0000 - val_fp: 260.0000 - val_loss: 0.0067 - val_precision: 0.9975 - val_recall: 0.9946 - val_tn: 194737.0000 - val_tp: 104432.0000\n",
      "Epoch 50/500\n",
      "147/147 - 3s - 17ms/step - fn: 356.0000 - fp: 406.0000 - loss: 419.8118 - precision: 0.9961 - recall: 0.9966 - tn: 194865.0000 - tp: 104373.0000 - val_fn: 588.0000 - val_fp: 253.0000 - val_loss: 0.0068 - val_precision: 0.9976 - val_recall: 0.9944 - val_tn: 194744.0000 - val_tp: 104415.0000\n",
      "Epoch 51/500\n",
      "147/147 - 3s - 17ms/step - fn: 314.0000 - fp: 373.0000 - loss: 404.3055 - precision: 0.9964 - recall: 0.9970 - tn: 194898.0000 - tp: 104415.0000 - val_fn: 534.0000 - val_fp: 283.0000 - val_loss: 0.0066 - val_precision: 0.9973 - val_recall: 0.9949 - val_tn: 194714.0000 - val_tp: 104469.0000\n",
      "Epoch 52/500\n",
      "147/147 - 2s - 17ms/step - fn: 346.0000 - fp: 383.0000 - loss: 404.4514 - precision: 0.9963 - recall: 0.9967 - tn: 194888.0000 - tp: 104383.0000 - val_fn: 512.0000 - val_fp: 352.0000 - val_loss: 0.0067 - val_precision: 0.9966 - val_recall: 0.9951 - val_tn: 194645.0000 - val_tp: 104491.0000\n",
      "Epoch 53/500\n",
      "147/147 - 2s - 17ms/step - fn: 322.0000 - fp: 379.0000 - loss: 399.6830 - precision: 0.9964 - recall: 0.9969 - tn: 194892.0000 - tp: 104407.0000 - val_fn: 372.0000 - val_fp: 387.0000 - val_loss: 0.0062 - val_precision: 0.9963 - val_recall: 0.9965 - val_tn: 194610.0000 - val_tp: 104631.0000\n",
      "Epoch 54/500\n",
      "147/147 - 2s - 17ms/step - fn: 298.0000 - fp: 366.0000 - loss: 390.3903 - precision: 0.9965 - recall: 0.9972 - tn: 194905.0000 - tp: 104431.0000 - val_fn: 479.0000 - val_fp: 328.0000 - val_loss: 0.0062 - val_precision: 0.9969 - val_recall: 0.9954 - val_tn: 194669.0000 - val_tp: 104524.0000\n",
      "Epoch 55/500\n",
      "147/147 - 2s - 16ms/step - fn: 297.0000 - fp: 362.0000 - loss: 381.9226 - precision: 0.9965 - recall: 0.9972 - tn: 194909.0000 - tp: 104432.0000 - val_fn: 448.0000 - val_fp: 297.0000 - val_loss: 0.0060 - val_precision: 0.9972 - val_recall: 0.9957 - val_tn: 194700.0000 - val_tp: 104555.0000\n",
      "Epoch 56/500\n",
      "147/147 - 2s - 17ms/step - fn: 322.0000 - fp: 366.0000 - loss: 382.4570 - precision: 0.9965 - recall: 0.9969 - tn: 194905.0000 - tp: 104407.0000 - val_fn: 327.0000 - val_fp: 397.0000 - val_loss: 0.0059 - val_precision: 0.9962 - val_recall: 0.9969 - val_tn: 194600.0000 - val_tp: 104676.0000\n",
      "Epoch 57/500\n",
      "147/147 - 2s - 17ms/step - fn: 322.0000 - fp: 366.0000 - loss: 385.2175 - precision: 0.9965 - recall: 0.9969 - tn: 194905.0000 - tp: 104407.0000 - val_fn: 463.0000 - val_fp: 295.0000 - val_loss: 0.0060 - val_precision: 0.9972 - val_recall: 0.9956 - val_tn: 194702.0000 - val_tp: 104540.0000\n",
      "Epoch 58/500\n",
      "147/147 - 3s - 17ms/step - fn: 303.0000 - fp: 336.0000 - loss: 368.0474 - precision: 0.9968 - recall: 0.9971 - tn: 194935.0000 - tp: 104426.0000 - val_fn: 354.0000 - val_fp: 344.0000 - val_loss: 0.0057 - val_precision: 0.9967 - val_recall: 0.9966 - val_tn: 194653.0000 - val_tp: 104649.0000\n",
      "Epoch 59/500\n",
      "147/147 - 2s - 17ms/step - fn: 307.0000 - fp: 342.0000 - loss: 371.6464 - precision: 0.9967 - recall: 0.9971 - tn: 194929.0000 - tp: 104422.0000 - val_fn: 269.0000 - val_fp: 394.0000 - val_loss: 0.0055 - val_precision: 0.9963 - val_recall: 0.9974 - val_tn: 194603.0000 - val_tp: 104734.0000\n",
      "Epoch 60/500\n",
      "147/147 - 2s - 17ms/step - fn: 291.0000 - fp: 346.0000 - loss: 361.6124 - precision: 0.9967 - recall: 0.9972 - tn: 194925.0000 - tp: 104438.0000 - val_fn: 419.0000 - val_fp: 326.0000 - val_loss: 0.0059 - val_precision: 0.9969 - val_recall: 0.9960 - val_tn: 194671.0000 - val_tp: 104584.0000\n",
      "Epoch 61/500\n",
      "147/147 - 2s - 17ms/step - fn: 303.0000 - fp: 350.0000 - loss: 357.4589 - precision: 0.9967 - recall: 0.9971 - tn: 194921.0000 - tp: 104426.0000 - val_fn: 422.0000 - val_fp: 288.0000 - val_loss: 0.0056 - val_precision: 0.9973 - val_recall: 0.9960 - val_tn: 194709.0000 - val_tp: 104581.0000\n",
      "Epoch 62/500\n",
      "147/147 - 2s - 17ms/step - fn: 288.0000 - fp: 335.0000 - loss: 353.7833 - precision: 0.9968 - recall: 0.9973 - tn: 194936.0000 - tp: 104441.0000 - val_fn: 391.0000 - val_fp: 362.0000 - val_loss: 0.0058 - val_precision: 0.9966 - val_recall: 0.9963 - val_tn: 194635.0000 - val_tp: 104612.0000\n",
      "Epoch 63/500\n",
      "147/147 - 2s - 17ms/step - fn: 304.0000 - fp: 350.0000 - loss: 356.0897 - precision: 0.9967 - recall: 0.9971 - tn: 194921.0000 - tp: 104425.0000 - val_fn: 556.0000 - val_fp: 233.0000 - val_loss: 0.0061 - val_precision: 0.9978 - val_recall: 0.9947 - val_tn: 194764.0000 - val_tp: 104447.0000\n",
      "Epoch 64/500\n",
      "147/147 - 2s - 16ms/step - fn: 296.0000 - fp: 307.0000 - loss: 341.7981 - precision: 0.9971 - recall: 0.9972 - tn: 194964.0000 - tp: 104433.0000 - val_fn: 394.0000 - val_fp: 288.0000 - val_loss: 0.0055 - val_precision: 0.9973 - val_recall: 0.9962 - val_tn: 194709.0000 - val_tp: 104609.0000\n",
      "Epoch 65/500\n",
      "147/147 - 2s - 11ms/step - fn: 269.0000 - fp: 329.0000 - loss: 341.4179 - precision: 0.9969 - recall: 0.9974 - tn: 194942.0000 - tp: 104460.0000 - val_fn: 405.0000 - val_fp: 275.0000 - val_loss: 0.0054 - val_precision: 0.9974 - val_recall: 0.9961 - val_tn: 194722.0000 - val_tp: 104598.0000\n",
      "Epoch 66/500\n",
      "147/147 - 2s - 11ms/step - fn: 281.0000 - fp: 308.0000 - loss: 339.9396 - precision: 0.9971 - recall: 0.9973 - tn: 194963.0000 - tp: 104448.0000 - val_fn: 339.0000 - val_fp: 309.0000 - val_loss: 0.0054 - val_precision: 0.9971 - val_recall: 0.9968 - val_tn: 194688.0000 - val_tp: 104664.0000\n",
      "Epoch 67/500\n",
      "147/147 - 2s - 12ms/step - fn: 295.0000 - fp: 322.0000 - loss: 343.3907 - precision: 0.9969 - recall: 0.9972 - tn: 194949.0000 - tp: 104434.0000 - val_fn: 474.0000 - val_fp: 238.0000 - val_loss: 0.0056 - val_precision: 0.9977 - val_recall: 0.9955 - val_tn: 194759.0000 - val_tp: 104529.0000\n",
      "Epoch 68/500\n",
      "147/147 - 2s - 10ms/step - fn: 270.0000 - fp: 304.0000 - loss: 323.8628 - precision: 0.9971 - recall: 0.9974 - tn: 194967.0000 - tp: 104459.0000 - val_fn: 360.0000 - val_fp: 309.0000 - val_loss: 0.0054 - val_precision: 0.9971 - val_recall: 0.9966 - val_tn: 194688.0000 - val_tp: 104643.0000\n",
      "Epoch 69/500\n",
      "147/147 - 2s - 11ms/step - fn: 262.0000 - fp: 311.0000 - loss: 319.2589 - precision: 0.9970 - recall: 0.9975 - tn: 194960.0000 - tp: 104467.0000 - val_fn: 351.0000 - val_fp: 299.0000 - val_loss: 0.0052 - val_precision: 0.9972 - val_recall: 0.9967 - val_tn: 194698.0000 - val_tp: 104652.0000\n",
      "Epoch 70/500\n",
      "147/147 - 2s - 11ms/step - fn: 262.0000 - fp: 309.0000 - loss: 320.9913 - precision: 0.9971 - recall: 0.9975 - tn: 194962.0000 - tp: 104467.0000 - val_fn: 411.0000 - val_fp: 257.0000 - val_loss: 0.0053 - val_precision: 0.9975 - val_recall: 0.9961 - val_tn: 194740.0000 - val_tp: 104592.0000\n",
      "Epoch 71/500\n",
      "147/147 - 2s - 10ms/step - fn: 260.0000 - fp: 305.0000 - loss: 319.3453 - precision: 0.9971 - recall: 0.9975 - tn: 194966.0000 - tp: 104469.0000 - val_fn: 370.0000 - val_fp: 294.0000 - val_loss: 0.0053 - val_precision: 0.9972 - val_recall: 0.9965 - val_tn: 194703.0000 - val_tp: 104633.0000\n",
      "Epoch 72/500\n",
      "147/147 - 2s - 10ms/step - fn: 261.0000 - fp: 310.0000 - loss: 322.5502 - precision: 0.9970 - recall: 0.9975 - tn: 194961.0000 - tp: 104468.0000 - val_fn: 316.0000 - val_fp: 332.0000 - val_loss: 0.0051 - val_precision: 0.9968 - val_recall: 0.9970 - val_tn: 194665.0000 - val_tp: 104687.0000\n",
      "Epoch 73/500\n",
      "147/147 - 2s - 11ms/step - fn: 266.0000 - fp: 310.0000 - loss: 314.8959 - precision: 0.9970 - recall: 0.9975 - tn: 194961.0000 - tp: 104463.0000 - val_fn: 381.0000 - val_fp: 270.0000 - val_loss: 0.0053 - val_precision: 0.9974 - val_recall: 0.9964 - val_tn: 194727.0000 - val_tp: 104622.0000\n",
      "Epoch 74/500\n",
      "147/147 - 2s - 10ms/step - fn: 264.0000 - fp: 297.0000 - loss: 315.3806 - precision: 0.9972 - recall: 0.9975 - tn: 194974.0000 - tp: 104465.0000 - val_fn: 418.0000 - val_fp: 281.0000 - val_loss: 0.0054 - val_precision: 0.9973 - val_recall: 0.9960 - val_tn: 194716.0000 - val_tp: 104585.0000\n",
      "Epoch 75/500\n",
      "147/147 - 2s - 11ms/step - fn: 253.0000 - fp: 295.0000 - loss: 303.1913 - precision: 0.9972 - recall: 0.9976 - tn: 194976.0000 - tp: 104476.0000 - val_fn: 312.0000 - val_fp: 304.0000 - val_loss: 0.0050 - val_precision: 0.9971 - val_recall: 0.9970 - val_tn: 194693.0000 - val_tp: 104691.0000\n",
      "Epoch 76/500\n",
      "147/147 - 2s - 11ms/step - fn: 258.0000 - fp: 301.0000 - loss: 308.8191 - precision: 0.9971 - recall: 0.9975 - tn: 194970.0000 - tp: 104471.0000 - val_fn: 306.0000 - val_fp: 312.0000 - val_loss: 0.0050 - val_precision: 0.9970 - val_recall: 0.9971 - val_tn: 194685.0000 - val_tp: 104697.0000\n",
      "Epoch 77/500\n",
      "147/147 - 2s - 11ms/step - fn: 246.0000 - fp: 297.0000 - loss: 304.3747 - precision: 0.9972 - recall: 0.9977 - tn: 194974.0000 - tp: 104483.0000 - val_fn: 517.0000 - val_fp: 182.0000 - val_loss: 0.0053 - val_precision: 0.9983 - val_recall: 0.9951 - val_tn: 194815.0000 - val_tp: 104486.0000\n",
      "Epoch 78/500\n",
      "147/147 - 2s - 11ms/step - fn: 233.0000 - fp: 273.0000 - loss: 293.9623 - precision: 0.9974 - recall: 0.9978 - tn: 194998.0000 - tp: 104496.0000 - val_fn: 395.0000 - val_fp: 283.0000 - val_loss: 0.0053 - val_precision: 0.9973 - val_recall: 0.9962 - val_tn: 194714.0000 - val_tp: 104608.0000\n",
      "Epoch 79/500\n",
      "147/147 - 2s - 11ms/step - fn: 242.0000 - fp: 282.0000 - loss: 302.8009 - precision: 0.9973 - recall: 0.9977 - tn: 194989.0000 - tp: 104487.0000 - val_fn: 204.0000 - val_fp: 414.0000 - val_loss: 0.0050 - val_precision: 0.9961 - val_recall: 0.9981 - val_tn: 194583.0000 - val_tp: 104799.0000\n",
      "Epoch 80/500\n",
      "147/147 - 2s - 12ms/step - fn: 243.0000 - fp: 281.0000 - loss: 292.1219 - precision: 0.9973 - recall: 0.9977 - tn: 194990.0000 - tp: 104486.0000 - val_fn: 399.0000 - val_fp: 238.0000 - val_loss: 0.0050 - val_precision: 0.9977 - val_recall: 0.9962 - val_tn: 194759.0000 - val_tp: 104604.0000\n",
      "Epoch 81/500\n",
      "147/147 - 2s - 13ms/step - fn: 239.0000 - fp: 274.0000 - loss: 295.0193 - precision: 0.9974 - recall: 0.9977 - tn: 194997.0000 - tp: 104490.0000 - val_fn: 353.0000 - val_fp: 262.0000 - val_loss: 0.0049 - val_precision: 0.9975 - val_recall: 0.9966 - val_tn: 194735.0000 - val_tp: 104650.0000\n",
      "Epoch 82/500\n",
      "147/147 - 2s - 13ms/step - fn: 218.0000 - fp: 273.0000 - loss: 279.0054 - precision: 0.9974 - recall: 0.9979 - tn: 194998.0000 - tp: 104511.0000 - val_fn: 415.0000 - val_fp: 198.0000 - val_loss: 0.0048 - val_precision: 0.9981 - val_recall: 0.9960 - val_tn: 194799.0000 - val_tp: 104588.0000\n",
      "Epoch 83/500\n",
      "147/147 - 2s - 12ms/step - fn: 235.0000 - fp: 265.0000 - loss: 282.6876 - precision: 0.9975 - recall: 0.9978 - tn: 195006.0000 - tp: 104494.0000 - val_fn: 379.0000 - val_fp: 251.0000 - val_loss: 0.0050 - val_precision: 0.9976 - val_recall: 0.9964 - val_tn: 194746.0000 - val_tp: 104624.0000\n",
      "Epoch 84/500\n",
      "147/147 - 2s - 11ms/step - fn: 231.0000 - fp: 289.0000 - loss: 285.0266 - precision: 0.9972 - recall: 0.9978 - tn: 194982.0000 - tp: 104498.0000 - val_fn: 354.0000 - val_fp: 340.0000 - val_loss: 0.0053 - val_precision: 0.9968 - val_recall: 0.9966 - val_tn: 194657.0000 - val_tp: 104649.0000\n",
      "Epoch 85/500\n",
      "147/147 - 2s - 11ms/step - fn: 239.0000 - fp: 277.0000 - loss: 284.2245 - precision: 0.9974 - recall: 0.9977 - tn: 194994.0000 - tp: 104490.0000 - val_fn: 308.0000 - val_fp: 291.0000 - val_loss: 0.0048 - val_precision: 0.9972 - val_recall: 0.9971 - val_tn: 194706.0000 - val_tp: 104695.0000\n",
      "Epoch 86/500\n",
      "147/147 - 2s - 11ms/step - fn: 216.0000 - fp: 251.0000 - loss: 271.4278 - precision: 0.9976 - recall: 0.9979 - tn: 195020.0000 - tp: 104513.0000 - val_fn: 308.0000 - val_fp: 316.0000 - val_loss: 0.0048 - val_precision: 0.9970 - val_recall: 0.9971 - val_tn: 194681.0000 - val_tp: 104695.0000\n",
      "Epoch 87/500\n",
      "147/147 - 2s - 12ms/step - fn: 237.0000 - fp: 268.0000 - loss: 278.1760 - precision: 0.9974 - recall: 0.9977 - tn: 195003.0000 - tp: 104492.0000 - val_fn: 381.0000 - val_fp: 287.0000 - val_loss: 0.0050 - val_precision: 0.9973 - val_recall: 0.9964 - val_tn: 194710.0000 - val_tp: 104622.0000\n",
      "Epoch 88/500\n",
      "147/147 - 2s - 11ms/step - fn: 225.0000 - fp: 249.0000 - loss: 273.6223 - precision: 0.9976 - recall: 0.9979 - tn: 195022.0000 - tp: 104504.0000 - val_fn: 339.0000 - val_fp: 302.0000 - val_loss: 0.0049 - val_precision: 0.9971 - val_recall: 0.9968 - val_tn: 194695.0000 - val_tp: 104664.0000\n",
      "Epoch 89/500\n",
      "147/147 - 2s - 11ms/step - fn: 206.0000 - fp: 267.0000 - loss: 266.0719 - precision: 0.9975 - recall: 0.9980 - tn: 195004.0000 - tp: 104523.0000 - val_fn: 418.0000 - val_fp: 216.0000 - val_loss: 0.0048 - val_precision: 0.9979 - val_recall: 0.9960 - val_tn: 194781.0000 - val_tp: 104585.0000\n",
      "Epoch 90/500\n",
      "147/147 - 2s - 11ms/step - fn: 218.0000 - fp: 245.0000 - loss: 262.0887 - precision: 0.9977 - recall: 0.9979 - tn: 195026.0000 - tp: 104511.0000 - val_fn: 377.0000 - val_fp: 266.0000 - val_loss: 0.0048 - val_precision: 0.9975 - val_recall: 0.9964 - val_tn: 194731.0000 - val_tp: 104626.0000\n",
      "Epoch 91/500\n",
      "147/147 - 2s - 11ms/step - fn: 229.0000 - fp: 256.0000 - loss: 264.4639 - precision: 0.9976 - recall: 0.9978 - tn: 195015.0000 - tp: 104500.0000 - val_fn: 279.0000 - val_fp: 304.0000 - val_loss: 0.0045 - val_precision: 0.9971 - val_recall: 0.9973 - val_tn: 194693.0000 - val_tp: 104724.0000\n",
      "Epoch 92/500\n",
      "147/147 - 2s - 11ms/step - fn: 209.0000 - fp: 260.0000 - loss: 261.0714 - precision: 0.9975 - recall: 0.9980 - tn: 195011.0000 - tp: 104520.0000 - val_fn: 336.0000 - val_fp: 260.0000 - val_loss: 0.0046 - val_precision: 0.9975 - val_recall: 0.9968 - val_tn: 194737.0000 - val_tp: 104667.0000\n",
      "Epoch 93/500\n",
      "147/147 - 2s - 10ms/step - fn: 209.0000 - fp: 260.0000 - loss: 261.7484 - precision: 0.9975 - recall: 0.9980 - tn: 195011.0000 - tp: 104520.0000 - val_fn: 366.0000 - val_fp: 223.0000 - val_loss: 0.0046 - val_precision: 0.9979 - val_recall: 0.9965 - val_tn: 194774.0000 - val_tp: 104637.0000\n",
      "Epoch 94/500\n",
      "147/147 - 2s - 11ms/step - fn: 201.0000 - fp: 228.0000 - loss: 242.8432 - precision: 0.9978 - recall: 0.9981 - tn: 195043.0000 - tp: 104528.0000 - val_fn: 310.0000 - val_fp: 267.0000 - val_loss: 0.0045 - val_precision: 0.9975 - val_recall: 0.9970 - val_tn: 194730.0000 - val_tp: 104693.0000\n",
      "Epoch 95/500\n",
      "147/147 - 2s - 11ms/step - fn: 212.0000 - fp: 238.0000 - loss: 259.0421 - precision: 0.9977 - recall: 0.9980 - tn: 195033.0000 - tp: 104517.0000 - val_fn: 326.0000 - val_fp: 267.0000 - val_loss: 0.0046 - val_precision: 0.9975 - val_recall: 0.9969 - val_tn: 194730.0000 - val_tp: 104677.0000\n",
      "Epoch 96/500\n",
      "147/147 - 2s - 12ms/step - fn: 230.0000 - fp: 251.0000 - loss: 271.2237 - precision: 0.9976 - recall: 0.9978 - tn: 195020.0000 - tp: 104499.0000 - val_fn: 321.0000 - val_fp: 267.0000 - val_loss: 0.0046 - val_precision: 0.9975 - val_recall: 0.9969 - val_tn: 194730.0000 - val_tp: 104682.0000\n",
      "Epoch 97/500\n",
      "147/147 - 2s - 13ms/step - fn: 201.0000 - fp: 237.0000 - loss: 251.2156 - precision: 0.9977 - recall: 0.9981 - tn: 195034.0000 - tp: 104528.0000 - val_fn: 291.0000 - val_fp: 241.0000 - val_loss: 0.0042 - val_precision: 0.9977 - val_recall: 0.9972 - val_tn: 194756.0000 - val_tp: 104712.0000\n",
      "Epoch 98/500\n",
      "147/147 - 2s - 13ms/step - fn: 212.0000 - fp: 241.0000 - loss: 250.8166 - precision: 0.9977 - recall: 0.9980 - tn: 195030.0000 - tp: 104517.0000 - val_fn: 287.0000 - val_fp: 285.0000 - val_loss: 0.0044 - val_precision: 0.9973 - val_recall: 0.9973 - val_tn: 194712.0000 - val_tp: 104716.0000\n",
      "Epoch 99/500\n",
      "147/147 - 2s - 13ms/step - fn: 199.0000 - fp: 250.0000 - loss: 253.6400 - precision: 0.9976 - recall: 0.9981 - tn: 195021.0000 - tp: 104530.0000 - val_fn: 358.0000 - val_fp: 268.0000 - val_loss: 0.0047 - val_precision: 0.9974 - val_recall: 0.9966 - val_tn: 194729.0000 - val_tp: 104645.0000\n",
      "Epoch 100/500\n",
      "147/147 - 2s - 12ms/step - fn: 195.0000 - fp: 247.0000 - loss: 249.7954 - precision: 0.9976 - recall: 0.9981 - tn: 195024.0000 - tp: 104534.0000 - val_fn: 288.0000 - val_fp: 288.0000 - val_loss: 0.0044 - val_precision: 0.9973 - val_recall: 0.9973 - val_tn: 194709.0000 - val_tp: 104715.0000\n",
      "Epoch 101/500\n",
      "147/147 - 2s - 12ms/step - fn: 207.0000 - fp: 255.0000 - loss: 252.4196 - precision: 0.9976 - recall: 0.9980 - tn: 195016.0000 - tp: 104522.0000 - val_fn: 368.0000 - val_fp: 247.0000 - val_loss: 0.0048 - val_precision: 0.9976 - val_recall: 0.9965 - val_tn: 194750.0000 - val_tp: 104635.0000\n",
      "Epoch 102/500\n",
      "147/147 - 2s - 13ms/step - fn: 191.0000 - fp: 220.0000 - loss: 238.0367 - precision: 0.9979 - recall: 0.9982 - tn: 195051.0000 - tp: 104538.0000 - val_fn: 360.0000 - val_fp: 244.0000 - val_loss: 0.0045 - val_precision: 0.9977 - val_recall: 0.9966 - val_tn: 194753.0000 - val_tp: 104643.0000\n",
      "Epoch 103/500\n",
      "147/147 - 2s - 13ms/step - fn: 221.0000 - fp: 247.0000 - loss: 249.5495 - precision: 0.9976 - recall: 0.9979 - tn: 195024.0000 - tp: 104508.0000 - val_fn: 325.0000 - val_fp: 229.0000 - val_loss: 0.0043 - val_precision: 0.9978 - val_recall: 0.9969 - val_tn: 194768.0000 - val_tp: 104678.0000\n",
      "Epoch 104/500\n",
      "147/147 - 2s - 12ms/step - fn: 206.0000 - fp: 237.0000 - loss: 255.6028 - precision: 0.9977 - recall: 0.9980 - tn: 195034.0000 - tp: 104523.0000 - val_fn: 259.0000 - val_fp: 281.0000 - val_loss: 0.0041 - val_precision: 0.9973 - val_recall: 0.9975 - val_tn: 194716.0000 - val_tp: 104744.0000\n",
      "Epoch 105/500\n",
      "147/147 - 2s - 12ms/step - fn: 200.0000 - fp: 244.0000 - loss: 253.3236 - precision: 0.9977 - recall: 0.9981 - tn: 195027.0000 - tp: 104529.0000 - val_fn: 396.0000 - val_fp: 204.0000 - val_loss: 0.0046 - val_precision: 0.9981 - val_recall: 0.9962 - val_tn: 194793.0000 - val_tp: 104607.0000\n",
      "Epoch 106/500\n",
      "147/147 - 2s - 12ms/step - fn: 186.0000 - fp: 235.0000 - loss: 238.7103 - precision: 0.9978 - recall: 0.9982 - tn: 195036.0000 - tp: 104543.0000 - val_fn: 274.0000 - val_fp: 304.0000 - val_loss: 0.0044 - val_precision: 0.9971 - val_recall: 0.9974 - val_tn: 194693.0000 - val_tp: 104729.0000\n",
      "Epoch 107/500\n",
      "147/147 - 2s - 12ms/step - fn: 210.0000 - fp: 248.0000 - loss: 242.7864 - precision: 0.9976 - recall: 0.9980 - tn: 195023.0000 - tp: 104519.0000 - val_fn: 349.0000 - val_fp: 246.0000 - val_loss: 0.0046 - val_precision: 0.9977 - val_recall: 0.9967 - val_tn: 194751.0000 - val_tp: 104654.0000\n",
      "Epoch 108/500\n",
      "147/147 - 2s - 12ms/step - fn: 190.0000 - fp: 234.0000 - loss: 237.1471 - precision: 0.9978 - recall: 0.9982 - tn: 195037.0000 - tp: 104539.0000 - val_fn: 318.0000 - val_fp: 273.0000 - val_loss: 0.0046 - val_precision: 0.9974 - val_recall: 0.9970 - val_tn: 194724.0000 - val_tp: 104685.0000\n",
      "Epoch 109/500\n",
      "147/147 - 2s - 12ms/step - fn: 188.0000 - fp: 237.0000 - loss: 234.4327 - precision: 0.9977 - recall: 0.9982 - tn: 195034.0000 - tp: 104541.0000 - val_fn: 301.0000 - val_fp: 235.0000 - val_loss: 0.0041 - val_precision: 0.9978 - val_recall: 0.9971 - val_tn: 194762.0000 - val_tp: 104702.0000\n",
      "Epoch 110/500\n",
      "147/147 - 2s - 11ms/step - fn: 208.0000 - fp: 247.0000 - loss: 242.0499 - precision: 0.9976 - recall: 0.9980 - tn: 195024.0000 - tp: 104521.0000 - val_fn: 287.0000 - val_fp: 247.0000 - val_loss: 0.0042 - val_precision: 0.9976 - val_recall: 0.9973 - val_tn: 194750.0000 - val_tp: 104716.0000\n",
      "Epoch 111/500\n",
      "147/147 - 2s - 12ms/step - fn: 202.0000 - fp: 246.0000 - loss: 246.2281 - precision: 0.9977 - recall: 0.9981 - tn: 195025.0000 - tp: 104527.0000 - val_fn: 292.0000 - val_fp: 255.0000 - val_loss: 0.0043 - val_precision: 0.9976 - val_recall: 0.9972 - val_tn: 194742.0000 - val_tp: 104711.0000\n",
      "Epoch 112/500\n",
      "147/147 - 2s - 12ms/step - fn: 198.0000 - fp: 248.0000 - loss: 246.3427 - precision: 0.9976 - recall: 0.9981 - tn: 195023.0000 - tp: 104531.0000 - val_fn: 404.0000 - val_fp: 200.0000 - val_loss: 0.0046 - val_precision: 0.9981 - val_recall: 0.9962 - val_tn: 194797.0000 - val_tp: 104599.0000\n",
      "Epoch 113/500\n",
      "147/147 - 2s - 12ms/step - fn: 199.0000 - fp: 201.0000 - loss: 226.1617 - precision: 0.9981 - recall: 0.9981 - tn: 195070.0000 - tp: 104530.0000 - val_fn: 313.0000 - val_fp: 253.0000 - val_loss: 0.0042 - val_precision: 0.9976 - val_recall: 0.9970 - val_tn: 194744.0000 - val_tp: 104690.0000\n",
      "Epoch 114/500\n",
      "147/147 - 2s - 13ms/step - fn: 191.0000 - fp: 222.0000 - loss: 223.4830 - precision: 0.9979 - recall: 0.9982 - tn: 195049.0000 - tp: 104538.0000 - val_fn: 293.0000 - val_fp: 391.0000 - val_loss: 0.0051 - val_precision: 0.9963 - val_recall: 0.9972 - val_tn: 194606.0000 - val_tp: 104710.0000\n",
      "Epoch 115/500\n",
      "147/147 - 2s - 13ms/step - fn: 193.0000 - fp: 226.0000 - loss: 231.2878 - precision: 0.9978 - recall: 0.9982 - tn: 195045.0000 - tp: 104536.0000 - val_fn: 295.0000 - val_fp: 275.0000 - val_loss: 0.0042 - val_precision: 0.9974 - val_recall: 0.9972 - val_tn: 194722.0000 - val_tp: 104708.0000\n",
      "Epoch 116/500\n",
      "147/147 - 2s - 12ms/step - fn: 212.0000 - fp: 235.0000 - loss: 237.5185 - precision: 0.9978 - recall: 0.9980 - tn: 195036.0000 - tp: 104517.0000 - val_fn: 308.0000 - val_fp: 224.0000 - val_loss: 0.0041 - val_precision: 0.9979 - val_recall: 0.9971 - val_tn: 194773.0000 - val_tp: 104695.0000\n",
      "Epoch 117/500\n",
      "147/147 - 2s - 12ms/step - fn: 184.0000 - fp: 226.0000 - loss: 224.8187 - precision: 0.9978 - recall: 0.9982 - tn: 195045.0000 - tp: 104545.0000 - val_fn: 247.0000 - val_fp: 283.0000 - val_loss: 0.0041 - val_precision: 0.9973 - val_recall: 0.9976 - val_tn: 194714.0000 - val_tp: 104756.0000\n",
      "Epoch 118/500\n",
      "147/147 - 2s - 12ms/step - fn: 181.0000 - fp: 218.0000 - loss: 227.7935 - precision: 0.9979 - recall: 0.9983 - tn: 195053.0000 - tp: 104548.0000 - val_fn: 383.0000 - val_fp: 227.0000 - val_loss: 0.0045 - val_precision: 0.9978 - val_recall: 0.9964 - val_tn: 194770.0000 - val_tp: 104620.0000\n",
      "Epoch 119/500\n",
      "147/147 - 2s - 12ms/step - fn: 161.0000 - fp: 222.0000 - loss: 221.1347 - precision: 0.9979 - recall: 0.9985 - tn: 195049.0000 - tp: 104568.0000 - val_fn: 223.0000 - val_fp: 298.0000 - val_loss: 0.0040 - val_precision: 0.9972 - val_recall: 0.9979 - val_tn: 194699.0000 - val_tp: 104780.0000\n",
      "Epoch 120/500\n",
      "147/147 - 2s - 13ms/step - fn: 186.0000 - fp: 212.0000 - loss: 219.8452 - precision: 0.9980 - recall: 0.9982 - tn: 195059.0000 - tp: 104543.0000 - val_fn: 358.0000 - val_fp: 194.0000 - val_loss: 0.0041 - val_precision: 0.9981 - val_recall: 0.9966 - val_tn: 194803.0000 - val_tp: 104645.0000\n",
      "Epoch 121/500\n",
      "147/147 - 2s - 13ms/step - fn: 183.0000 - fp: 216.0000 - loss: 225.8900 - precision: 0.9979 - recall: 0.9983 - tn: 195055.0000 - tp: 104546.0000 - val_fn: 259.0000 - val_fp: 252.0000 - val_loss: 0.0040 - val_precision: 0.9976 - val_recall: 0.9975 - val_tn: 194745.0000 - val_tp: 104744.0000\n",
      "Epoch 122/500\n",
      "147/147 - 2s - 12ms/step - fn: 172.0000 - fp: 230.0000 - loss: 220.4521 - precision: 0.9978 - recall: 0.9984 - tn: 195041.0000 - tp: 104557.0000 - val_fn: 273.0000 - val_fp: 239.0000 - val_loss: 0.0040 - val_precision: 0.9977 - val_recall: 0.9974 - val_tn: 194758.0000 - val_tp: 104730.0000\n",
      "Epoch 123/500\n",
      "147/147 - 2s - 13ms/step - fn: 173.0000 - fp: 216.0000 - loss: 211.6760 - precision: 0.9979 - recall: 0.9983 - tn: 195055.0000 - tp: 104556.0000 - val_fn: 314.0000 - val_fp: 240.0000 - val_loss: 0.0042 - val_precision: 0.9977 - val_recall: 0.9970 - val_tn: 194757.0000 - val_tp: 104689.0000\n",
      "Epoch 124/500\n",
      "147/147 - 2s - 12ms/step - fn: 177.0000 - fp: 209.0000 - loss: 220.9679 - precision: 0.9980 - recall: 0.9983 - tn: 195062.0000 - tp: 104552.0000 - val_fn: 279.0000 - val_fp: 232.0000 - val_loss: 0.0040 - val_precision: 0.9978 - val_recall: 0.9973 - val_tn: 194765.0000 - val_tp: 104724.0000\n",
      "Epoch 125/500\n",
      "147/147 - 2s - 12ms/step - fn: 180.0000 - fp: 230.0000 - loss: 218.7935 - precision: 0.9978 - recall: 0.9983 - tn: 195041.0000 - tp: 104549.0000 - val_fn: 225.0000 - val_fp: 254.0000 - val_loss: 0.0037 - val_precision: 0.9976 - val_recall: 0.9979 - val_tn: 194743.0000 - val_tp: 104778.0000\n",
      "Epoch 126/500\n",
      "147/147 - 2s - 13ms/step - fn: 176.0000 - fp: 210.0000 - loss: 217.3625 - precision: 0.9980 - recall: 0.9983 - tn: 195061.0000 - tp: 104553.0000 - val_fn: 372.0000 - val_fp: 176.0000 - val_loss: 0.0042 - val_precision: 0.9983 - val_recall: 0.9965 - val_tn: 194821.0000 - val_tp: 104631.0000\n",
      "Epoch 127/500\n",
      "147/147 - 2s - 12ms/step - fn: 199.0000 - fp: 230.0000 - loss: 224.7029 - precision: 0.9978 - recall: 0.9981 - tn: 195041.0000 - tp: 104530.0000 - val_fn: 197.0000 - val_fp: 323.0000 - val_loss: 0.0040 - val_precision: 0.9969 - val_recall: 0.9981 - val_tn: 194674.0000 - val_tp: 104806.0000\n",
      "Epoch 128/500\n",
      "147/147 - 2s - 12ms/step - fn: 178.0000 - fp: 210.0000 - loss: 219.8823 - precision: 0.9980 - recall: 0.9983 - tn: 195061.0000 - tp: 104551.0000 - val_fn: 336.0000 - val_fp: 205.0000 - val_loss: 0.0041 - val_precision: 0.9980 - val_recall: 0.9968 - val_tn: 194792.0000 - val_tp: 104667.0000\n",
      "Epoch 129/500\n",
      "147/147 - 2s - 12ms/step - fn: 165.0000 - fp: 213.0000 - loss: 209.4638 - precision: 0.9980 - recall: 0.9984 - tn: 195058.0000 - tp: 104564.0000 - val_fn: 323.0000 - val_fp: 196.0000 - val_loss: 0.0040 - val_precision: 0.9981 - val_recall: 0.9969 - val_tn: 194801.0000 - val_tp: 104680.0000\n",
      "Epoch 130/500\n",
      "147/147 - 2s - 12ms/step - fn: 164.0000 - fp: 195.0000 - loss: 204.2555 - precision: 0.9981 - recall: 0.9984 - tn: 195076.0000 - tp: 104565.0000 - val_fn: 371.0000 - val_fp: 217.0000 - val_loss: 0.0044 - val_precision: 0.9979 - val_recall: 0.9965 - val_tn: 194780.0000 - val_tp: 104632.0000\n",
      "Epoch 131/500\n",
      "147/147 - 2s - 12ms/step - fn: 167.0000 - fp: 193.0000 - loss: 206.2634 - precision: 0.9982 - recall: 0.9984 - tn: 195078.0000 - tp: 104562.0000 - val_fn: 349.0000 - val_fp: 179.0000 - val_loss: 0.0040 - val_precision: 0.9983 - val_recall: 0.9967 - val_tn: 194818.0000 - val_tp: 104654.0000\n",
      "Epoch 132/500\n",
      "147/147 - 2s - 11ms/step - fn: 167.0000 - fp: 208.0000 - loss: 204.6335 - precision: 0.9980 - recall: 0.9984 - tn: 195063.0000 - tp: 104562.0000 - val_fn: 288.0000 - val_fp: 223.0000 - val_loss: 0.0039 - val_precision: 0.9979 - val_recall: 0.9973 - val_tn: 194774.0000 - val_tp: 104715.0000\n",
      "Epoch 133/500\n",
      "147/147 - 2s - 12ms/step - fn: 163.0000 - fp: 185.0000 - loss: 198.0356 - precision: 0.9982 - recall: 0.9984 - tn: 195086.0000 - tp: 104566.0000 - val_fn: 365.0000 - val_fp: 168.0000 - val_loss: 0.0040 - val_precision: 0.9984 - val_recall: 0.9965 - val_tn: 194829.0000 - val_tp: 104638.0000\n",
      "Epoch 134/500\n",
      "147/147 - 2s - 12ms/step - fn: 167.0000 - fp: 187.0000 - loss: 199.8659 - precision: 0.9982 - recall: 0.9984 - tn: 195084.0000 - tp: 104562.0000 - val_fn: 247.0000 - val_fp: 281.0000 - val_loss: 0.0039 - val_precision: 0.9973 - val_recall: 0.9976 - val_tn: 194716.0000 - val_tp: 104756.0000\n",
      "Epoch 135/500\n",
      "147/147 - 2s - 12ms/step - fn: 187.0000 - fp: 228.0000 - loss: 218.9381 - precision: 0.9978 - recall: 0.9982 - tn: 195043.0000 - tp: 104542.0000 - val_fn: 501.0000 - val_fp: 239.0000 - val_loss: 0.0059 - val_precision: 0.9977 - val_recall: 0.9952 - val_tn: 194758.0000 - val_tp: 104502.0000\n",
      "Epoch 136/500\n",
      "147/147 - 2s - 12ms/step - fn: 177.0000 - fp: 212.0000 - loss: 211.3925 - precision: 0.9980 - recall: 0.9983 - tn: 195059.0000 - tp: 104552.0000 - val_fn: 201.0000 - val_fp: 301.0000 - val_loss: 0.0039 - val_precision: 0.9971 - val_recall: 0.9981 - val_tn: 194696.0000 - val_tp: 104802.0000\n",
      "Epoch 137/500\n",
      "147/147 - 2s - 12ms/step - fn: 162.0000 - fp: 185.0000 - loss: 197.0633 - precision: 0.9982 - recall: 0.9985 - tn: 195086.0000 - tp: 104567.0000 - val_fn: 353.0000 - val_fp: 196.0000 - val_loss: 0.0042 - val_precision: 0.9981 - val_recall: 0.9966 - val_tn: 194801.0000 - val_tp: 104650.0000\n",
      "Epoch 138/500\n",
      "147/147 - 2s - 12ms/step - fn: 161.0000 - fp: 198.0000 - loss: 196.5372 - precision: 0.9981 - recall: 0.9985 - tn: 195073.0000 - tp: 104568.0000 - val_fn: 322.0000 - val_fp: 197.0000 - val_loss: 0.0040 - val_precision: 0.9981 - val_recall: 0.9969 - val_tn: 194800.0000 - val_tp: 104681.0000\n",
      "Epoch 139/500\n",
      "147/147 - 2s - 11ms/step - fn: 159.0000 - fp: 195.0000 - loss: 199.5686 - precision: 0.9981 - recall: 0.9985 - tn: 195076.0000 - tp: 104570.0000 - val_fn: 271.0000 - val_fp: 226.0000 - val_loss: 0.0038 - val_precision: 0.9978 - val_recall: 0.9974 - val_tn: 194771.0000 - val_tp: 104732.0000\n",
      "Epoch 140/500\n",
      "147/147 - 2s - 13ms/step - fn: 186.0000 - fp: 220.0000 - loss: 209.9566 - precision: 0.9979 - recall: 0.9982 - tn: 195051.0000 - tp: 104543.0000 - val_fn: 339.0000 - val_fp: 196.0000 - val_loss: 0.0040 - val_precision: 0.9981 - val_recall: 0.9968 - val_tn: 194801.0000 - val_tp: 104664.0000\n",
      "Epoch 141/500\n",
      "147/147 - 2s - 12ms/step - fn: 178.0000 - fp: 220.0000 - loss: 214.0444 - precision: 0.9979 - recall: 0.9983 - tn: 195051.0000 - tp: 104551.0000 - val_fn: 352.0000 - val_fp: 187.0000 - val_loss: 0.0041 - val_precision: 0.9982 - val_recall: 0.9966 - val_tn: 194810.0000 - val_tp: 104651.0000\n",
      "Epoch 142/500\n",
      "147/147 - 2s - 11ms/step - fn: 150.0000 - fp: 182.0000 - loss: 197.1614 - precision: 0.9983 - recall: 0.9986 - tn: 195089.0000 - tp: 104579.0000 - val_fn: 397.0000 - val_fp: 139.0000 - val_loss: 0.0041 - val_precision: 0.9987 - val_recall: 0.9962 - val_tn: 194858.0000 - val_tp: 104606.0000\n",
      "Epoch 143/500\n",
      "147/147 - 2s - 11ms/step - fn: 175.0000 - fp: 212.0000 - loss: 207.4218 - precision: 0.9980 - recall: 0.9983 - tn: 195059.0000 - tp: 104554.0000 - val_fn: 224.0000 - val_fp: 245.0000 - val_loss: 0.0037 - val_precision: 0.9977 - val_recall: 0.9979 - val_tn: 194752.0000 - val_tp: 104779.0000\n",
      "Epoch 144/500\n",
      "147/147 - 3s - 18ms/step - fn: 157.0000 - fp: 194.0000 - loss: 201.6848 - precision: 0.9981 - recall: 0.9985 - tn: 195077.0000 - tp: 104572.0000 - val_fn: 238.0000 - val_fp: 239.0000 - val_loss: 0.0037 - val_precision: 0.9977 - val_recall: 0.9977 - val_tn: 194758.0000 - val_tp: 104765.0000\n",
      "Epoch 145/500\n",
      "147/147 - 2s - 11ms/step - fn: 166.0000 - fp: 203.0000 - loss: 212.1014 - precision: 0.9981 - recall: 0.9984 - tn: 195068.0000 - tp: 104563.0000 - val_fn: 260.0000 - val_fp: 260.0000 - val_loss: 0.0040 - val_precision: 0.9975 - val_recall: 0.9975 - val_tn: 194737.0000 - val_tp: 104743.0000\n",
      "Epoch 146/500\n",
      "147/147 - 2s - 11ms/step - fn: 180.0000 - fp: 208.0000 - loss: 209.0840 - precision: 0.9980 - recall: 0.9983 - tn: 195063.0000 - tp: 104549.0000 - val_fn: 329.0000 - val_fp: 189.0000 - val_loss: 0.0040 - val_precision: 0.9982 - val_recall: 0.9969 - val_tn: 194808.0000 - val_tp: 104674.0000\n",
      "Epoch 147/500\n",
      "147/147 - 2s - 12ms/step - fn: 159.0000 - fp: 191.0000 - loss: 195.3830 - precision: 0.9982 - recall: 0.9985 - tn: 195080.0000 - tp: 104570.0000 - val_fn: 308.0000 - val_fp: 212.0000 - val_loss: 0.0040 - val_precision: 0.9980 - val_recall: 0.9971 - val_tn: 194785.0000 - val_tp: 104695.0000\n",
      "Epoch 148/500\n",
      "147/147 - 2s - 12ms/step - fn: 152.0000 - fp: 174.0000 - loss: 191.7572 - precision: 0.9983 - recall: 0.9985 - tn: 195097.0000 - tp: 104577.0000 - val_fn: 316.0000 - val_fp: 224.0000 - val_loss: 0.0042 - val_precision: 0.9979 - val_recall: 0.9970 - val_tn: 194773.0000 - val_tp: 104687.0000\n",
      "Epoch 149/500\n",
      "147/147 - 2s - 12ms/step - fn: 182.0000 - fp: 204.0000 - loss: 202.2370 - precision: 0.9981 - recall: 0.9983 - tn: 195067.0000 - tp: 104547.0000 - val_fn: 323.0000 - val_fp: 230.0000 - val_loss: 0.0042 - val_precision: 0.9978 - val_recall: 0.9969 - val_tn: 194767.0000 - val_tp: 104680.0000\n",
      "Epoch 150/500\n",
      "147/147 - 2s - 11ms/step - fn: 156.0000 - fp: 186.0000 - loss: 189.0866 - precision: 0.9982 - recall: 0.9985 - tn: 195085.0000 - tp: 104573.0000 - val_fn: 266.0000 - val_fp: 251.0000 - val_loss: 0.0040 - val_precision: 0.9976 - val_recall: 0.9975 - val_tn: 194746.0000 - val_tp: 104737.0000\n",
      "Epoch 151/500\n",
      "147/147 - 2s - 11ms/step - fn: 181.0000 - fp: 228.0000 - loss: 210.4929 - precision: 0.9978 - recall: 0.9983 - tn: 195043.0000 - tp: 104548.0000 - val_fn: 441.0000 - val_fp: 200.0000 - val_loss: 0.0049 - val_precision: 0.9981 - val_recall: 0.9958 - val_tn: 194797.0000 - val_tp: 104562.0000\n",
      "Epoch 152/500\n",
      "147/147 - 2s - 10ms/step - fn: 160.0000 - fp: 198.0000 - loss: 198.1498 - precision: 0.9981 - recall: 0.9985 - tn: 195073.0000 - tp: 104569.0000 - val_fn: 293.0000 - val_fp: 206.0000 - val_loss: 0.0039 - val_precision: 0.9980 - val_recall: 0.9972 - val_tn: 194791.0000 - val_tp: 104710.0000\n",
      "Epoch 153/500\n",
      "147/147 - 2s - 11ms/step - fn: 158.0000 - fp: 209.0000 - loss: 196.5186 - precision: 0.9980 - recall: 0.9985 - tn: 195062.0000 - tp: 104571.0000 - val_fn: 301.0000 - val_fp: 187.0000 - val_loss: 0.0037 - val_precision: 0.9982 - val_recall: 0.9971 - val_tn: 194810.0000 - val_tp: 104702.0000\n",
      "Epoch 154/500\n",
      "147/147 - 2s - 11ms/step - fn: 168.0000 - fp: 194.0000 - loss: 200.4960 - precision: 0.9981 - recall: 0.9984 - tn: 195077.0000 - tp: 104561.0000 - val_fn: 268.0000 - val_fp: 193.0000 - val_loss: 0.0036 - val_precision: 0.9982 - val_recall: 0.9974 - val_tn: 194804.0000 - val_tp: 104735.0000\n",
      "Epoch 155/500\n",
      "147/147 - 2s - 12ms/step - fn: 140.0000 - fp: 175.0000 - loss: 175.5565 - precision: 0.9983 - recall: 0.9987 - tn: 195096.0000 - tp: 104589.0000 - val_fn: 255.0000 - val_fp: 213.0000 - val_loss: 0.0036 - val_precision: 0.9980 - val_recall: 0.9976 - val_tn: 194784.0000 - val_tp: 104748.0000\n",
      "Epoch 156/500\n",
      "147/147 - 2s - 11ms/step - fn: 159.0000 - fp: 202.0000 - loss: 191.5335 - precision: 0.9981 - recall: 0.9985 - tn: 195069.0000 - tp: 104570.0000 - val_fn: 466.0000 - val_fp: 152.0000 - val_loss: 0.0049 - val_precision: 0.9985 - val_recall: 0.9956 - val_tn: 194845.0000 - val_tp: 104537.0000\n",
      "Epoch 157/500\n",
      "147/147 - 2s - 12ms/step - fn: 154.0000 - fp: 183.0000 - loss: 188.7487 - precision: 0.9983 - recall: 0.9985 - tn: 195088.0000 - tp: 104575.0000 - val_fn: 248.0000 - val_fp: 221.0000 - val_loss: 0.0036 - val_precision: 0.9979 - val_recall: 0.9976 - val_tn: 194776.0000 - val_tp: 104755.0000\n",
      "Epoch 158/500\n",
      "147/147 - 2s - 13ms/step - fn: 144.0000 - fp: 181.0000 - loss: 184.5356 - precision: 0.9983 - recall: 0.9986 - tn: 195090.0000 - tp: 104585.0000 - val_fn: 262.0000 - val_fp: 229.0000 - val_loss: 0.0037 - val_precision: 0.9978 - val_recall: 0.9975 - val_tn: 194768.0000 - val_tp: 104741.0000\n",
      "Epoch 159/500\n",
      "147/147 - 2s - 12ms/step - fn: 148.0000 - fp: 188.0000 - loss: 187.4724 - precision: 0.9982 - recall: 0.9986 - tn: 195083.0000 - tp: 104581.0000 - val_fn: 335.0000 - val_fp: 199.0000 - val_loss: 0.0041 - val_precision: 0.9981 - val_recall: 0.9968 - val_tn: 194798.0000 - val_tp: 104668.0000\n",
      "Epoch 160/500\n",
      "147/147 - 2s - 13ms/step - fn: 152.0000 - fp: 176.0000 - loss: 188.1779 - precision: 0.9983 - recall: 0.9985 - tn: 195095.0000 - tp: 104577.0000 - val_fn: 339.0000 - val_fp: 207.0000 - val_loss: 0.0041 - val_precision: 0.9980 - val_recall: 0.9968 - val_tn: 194790.0000 - val_tp: 104664.0000\n",
      "Epoch 161/500\n",
      "147/147 - 2s - 11ms/step - fn: 130.0000 - fp: 164.0000 - loss: 175.0669 - precision: 0.9984 - recall: 0.9988 - tn: 195107.0000 - tp: 104599.0000 - val_fn: 310.0000 - val_fp: 204.0000 - val_loss: 0.0038 - val_precision: 0.9981 - val_recall: 0.9970 - val_tn: 194793.0000 - val_tp: 104693.0000\n",
      "Epoch 162/500\n",
      "147/147 - 2s - 11ms/step - fn: 148.0000 - fp: 168.0000 - loss: 173.6858 - precision: 0.9984 - recall: 0.9986 - tn: 195103.0000 - tp: 104581.0000 - val_fn: 251.0000 - val_fp: 236.0000 - val_loss: 0.0038 - val_precision: 0.9978 - val_recall: 0.9976 - val_tn: 194761.0000 - val_tp: 104752.0000\n",
      "Epoch 163/500\n",
      "147/147 - 2s - 12ms/step - fn: 153.0000 - fp: 176.0000 - loss: 175.0589 - precision: 0.9983 - recall: 0.9985 - tn: 195095.0000 - tp: 104576.0000 - val_fn: 428.0000 - val_fp: 119.0000 - val_loss: 0.0042 - val_precision: 0.9989 - val_recall: 0.9959 - val_tn: 194878.0000 - val_tp: 104575.0000\n",
      "Epoch 164/500\n",
      "147/147 - 2s - 11ms/step - fn: 141.0000 - fp: 158.0000 - loss: 174.1881 - precision: 0.9985 - recall: 0.9987 - tn: 195113.0000 - tp: 104588.0000 - val_fn: 254.0000 - val_fp: 215.0000 - val_loss: 0.0036 - val_precision: 0.9980 - val_recall: 0.9976 - val_tn: 194782.0000 - val_tp: 104749.0000\n",
      "Epoch 165/500\n",
      "147/147 - 2s - 12ms/step - fn: 142.0000 - fp: 182.0000 - loss: 177.3582 - precision: 0.9983 - recall: 0.9986 - tn: 195089.0000 - tp: 104587.0000 - val_fn: 399.0000 - val_fp: 196.0000 - val_loss: 0.0047 - val_precision: 0.9981 - val_recall: 0.9962 - val_tn: 194801.0000 - val_tp: 104604.0000\n",
      "Epoch 166/500\n",
      "147/147 - 2s - 14ms/step - fn: 156.0000 - fp: 181.0000 - loss: 187.8443 - precision: 0.9983 - recall: 0.9985 - tn: 195090.0000 - tp: 104573.0000 - val_fn: 410.0000 - val_fp: 162.0000 - val_loss: 0.0044 - val_precision: 0.9985 - val_recall: 0.9961 - val_tn: 194835.0000 - val_tp: 104593.0000\n",
      "Epoch 167/500\n",
      "147/147 - 2s - 12ms/step - fn: 144.0000 - fp: 185.0000 - loss: 174.4402 - precision: 0.9982 - recall: 0.9986 - tn: 195086.0000 - tp: 104585.0000 - val_fn: 327.0000 - val_fp: 181.0000 - val_loss: 0.0038 - val_precision: 0.9983 - val_recall: 0.9969 - val_tn: 194816.0000 - val_tp: 104676.0000\n",
      "Epoch 168/500\n",
      "147/147 - 2s - 11ms/step - fn: 148.0000 - fp: 178.0000 - loss: 179.3006 - precision: 0.9983 - recall: 0.9986 - tn: 195093.0000 - tp: 104581.0000 - val_fn: 360.0000 - val_fp: 158.0000 - val_loss: 0.0040 - val_precision: 0.9985 - val_recall: 0.9966 - val_tn: 194839.0000 - val_tp: 104643.0000\n",
      "Epoch 169/500\n",
      "147/147 - 2s - 11ms/step - fn: 132.0000 - fp: 186.0000 - loss: 176.9077 - precision: 0.9982 - recall: 0.9987 - tn: 195085.0000 - tp: 104597.0000 - val_fn: 391.0000 - val_fp: 157.0000 - val_loss: 0.0042 - val_precision: 0.9985 - val_recall: 0.9963 - val_tn: 194840.0000 - val_tp: 104612.0000\n",
      "Epoch 170/500\n",
      "147/147 - 2s - 11ms/step - fn: 141.0000 - fp: 176.0000 - loss: 172.1647 - precision: 0.9983 - recall: 0.9987 - tn: 195095.0000 - tp: 104588.0000 - val_fn: 212.0000 - val_fp: 280.0000 - val_loss: 0.0038 - val_precision: 0.9973 - val_recall: 0.9980 - val_tn: 194717.0000 - val_tp: 104791.0000\n",
      "Epoch 171/500\n",
      "147/147 - 2s - 12ms/step - fn: 119.0000 - fp: 169.0000 - loss: 166.5633 - precision: 0.9984 - recall: 0.9989 - tn: 195102.0000 - tp: 104610.0000 - val_fn: 356.0000 - val_fp: 174.0000 - val_loss: 0.0041 - val_precision: 0.9983 - val_recall: 0.9966 - val_tn: 194823.0000 - val_tp: 104647.0000\n",
      "Epoch 172/500\n",
      "147/147 - 2s - 11ms/step - fn: 137.0000 - fp: 174.0000 - loss: 177.6932 - precision: 0.9983 - recall: 0.9987 - tn: 195097.0000 - tp: 104592.0000 - val_fn: 320.0000 - val_fp: 177.0000 - val_loss: 0.0039 - val_precision: 0.9983 - val_recall: 0.9970 - val_tn: 194820.0000 - val_tp: 104683.0000\n",
      "Epoch 173/500\n",
      "147/147 - 2s - 11ms/step - fn: 140.0000 - fp: 175.0000 - loss: 177.1930 - precision: 0.9983 - recall: 0.9987 - tn: 195096.0000 - tp: 104589.0000 - val_fn: 302.0000 - val_fp: 179.0000 - val_loss: 0.0037 - val_precision: 0.9983 - val_recall: 0.9971 - val_tn: 194818.0000 - val_tp: 104701.0000\n",
      "Epoch 174/500\n",
      "147/147 - 2s - 12ms/step - fn: 145.0000 - fp: 181.0000 - loss: 182.1170 - precision: 0.9983 - recall: 0.9986 - tn: 195090.0000 - tp: 104584.0000 - val_fn: 268.0000 - val_fp: 269.0000 - val_loss: 0.0042 - val_precision: 0.9974 - val_recall: 0.9974 - val_tn: 194728.0000 - val_tp: 104735.0000\n",
      "Epoch 175/500\n",
      "147/147 - 2s - 11ms/step - fn: 143.0000 - fp: 189.0000 - loss: 179.9020 - precision: 0.9982 - recall: 0.9986 - tn: 195082.0000 - tp: 104586.0000 - val_fn: 278.0000 - val_fp: 181.0000 - val_loss: 0.0037 - val_precision: 0.9983 - val_recall: 0.9974 - val_tn: 194816.0000 - val_tp: 104725.0000\n",
      "Epoch 176/500\n",
      "147/147 - 2s - 11ms/step - fn: 156.0000 - fp: 191.0000 - loss: 186.5397 - precision: 0.9982 - recall: 0.9985 - tn: 195080.0000 - tp: 104573.0000 - val_fn: 323.0000 - val_fp: 183.0000 - val_loss: 0.0039 - val_precision: 0.9983 - val_recall: 0.9969 - val_tn: 194814.0000 - val_tp: 104680.0000\n",
      "Epoch 177/500\n",
      "147/147 - 2s - 11ms/step - fn: 137.0000 - fp: 170.0000 - loss: 174.4727 - precision: 0.9984 - recall: 0.9987 - tn: 195101.0000 - tp: 104592.0000 - val_fn: 406.0000 - val_fp: 132.0000 - val_loss: 0.0040 - val_precision: 0.9987 - val_recall: 0.9961 - val_tn: 194865.0000 - val_tp: 104597.0000\n",
      "Epoch 178/500\n",
      "147/147 - 2s - 11ms/step - fn: 125.0000 - fp: 178.0000 - loss: 162.6086 - precision: 0.9983 - recall: 0.9988 - tn: 195093.0000 - tp: 104604.0000 - val_fn: 356.0000 - val_fp: 192.0000 - val_loss: 0.0043 - val_precision: 0.9982 - val_recall: 0.9966 - val_tn: 194805.0000 - val_tp: 104647.0000\n",
      "Epoch 179/500\n",
      "147/147 - 2s - 11ms/step - fn: 141.0000 - fp: 186.0000 - loss: 183.2587 - precision: 0.9982 - recall: 0.9987 - tn: 195085.0000 - tp: 104588.0000 - val_fn: 261.0000 - val_fp: 198.0000 - val_loss: 0.0036 - val_precision: 0.9981 - val_recall: 0.9975 - val_tn: 194799.0000 - val_tp: 104742.0000\n",
      "Epoch 180/500\n",
      "147/147 - 2s - 11ms/step - fn: 140.0000 - fp: 181.0000 - loss: 177.5654 - precision: 0.9983 - recall: 0.9987 - tn: 195090.0000 - tp: 104589.0000 - val_fn: 316.0000 - val_fp: 172.0000 - val_loss: 0.0038 - val_precision: 0.9984 - val_recall: 0.9970 - val_tn: 194825.0000 - val_tp: 104687.0000\n",
      "Epoch 181/500\n",
      "147/147 - 2s - 11ms/step - fn: 126.0000 - fp: 163.0000 - loss: 164.8033 - precision: 0.9984 - recall: 0.9988 - tn: 195108.0000 - tp: 104603.0000 - val_fn: 385.0000 - val_fp: 140.0000 - val_loss: 0.0040 - val_precision: 0.9987 - val_recall: 0.9963 - val_tn: 194857.0000 - val_tp: 104618.0000\n",
      "Epoch 182/500\n",
      "147/147 - 2s - 11ms/step - fn: 152.0000 - fp: 180.0000 - loss: 182.8679 - precision: 0.9983 - recall: 0.9985 - tn: 195091.0000 - tp: 104577.0000 - val_fn: 238.0000 - val_fp: 211.0000 - val_loss: 0.0035 - val_precision: 0.9980 - val_recall: 0.9977 - val_tn: 194786.0000 - val_tp: 104765.0000\n",
      "Epoch 183/500\n",
      "147/147 - 2s - 11ms/step - fn: 130.0000 - fp: 175.0000 - loss: 175.5980 - precision: 0.9983 - recall: 0.9988 - tn: 195096.0000 - tp: 104599.0000 - val_fn: 297.0000 - val_fp: 204.0000 - val_loss: 0.0040 - val_precision: 0.9981 - val_recall: 0.9972 - val_tn: 194793.0000 - val_tp: 104706.0000\n",
      "Epoch 184/500\n",
      "147/147 - 2s - 12ms/step - fn: 141.0000 - fp: 167.0000 - loss: 171.3652 - precision: 0.9984 - recall: 0.9987 - tn: 195104.0000 - tp: 104588.0000 - val_fn: 407.0000 - val_fp: 148.0000 - val_loss: 0.0043 - val_precision: 0.9986 - val_recall: 0.9961 - val_tn: 194849.0000 - val_tp: 104596.0000\n",
      "Epoch 185/500\n",
      "147/147 - 2s - 11ms/step - fn: 139.0000 - fp: 174.0000 - loss: 174.6951 - precision: 0.9983 - recall: 0.9987 - tn: 195097.0000 - tp: 104590.0000 - val_fn: 366.0000 - val_fp: 159.0000 - val_loss: 0.0040 - val_precision: 0.9985 - val_recall: 0.9965 - val_tn: 194838.0000 - val_tp: 104637.0000\n",
      "Epoch 186/500\n",
      "147/147 - 2s - 12ms/step - fn: 134.0000 - fp: 171.0000 - loss: 165.1436 - precision: 0.9984 - recall: 0.9987 - tn: 195100.0000 - tp: 104595.0000 - val_fn: 200.0000 - val_fp: 244.0000 - val_loss: 0.0035 - val_precision: 0.9977 - val_recall: 0.9981 - val_tn: 194753.0000 - val_tp: 104803.0000\n",
      "Epoch 187/500\n",
      "147/147 - 2s - 11ms/step - fn: 144.0000 - fp: 183.0000 - loss: 172.9564 - precision: 0.9983 - recall: 0.9986 - tn: 195088.0000 - tp: 104585.0000 - val_fn: 412.0000 - val_fp: 142.0000 - val_loss: 0.0043 - val_precision: 0.9986 - val_recall: 0.9961 - val_tn: 194855.0000 - val_tp: 104591.0000\n",
      "Epoch 188/500\n",
      "147/147 - 2s - 11ms/step - fn: 146.0000 - fp: 183.0000 - loss: 181.1098 - precision: 0.9983 - recall: 0.9986 - tn: 195088.0000 - tp: 104583.0000 - val_fn: 273.0000 - val_fp: 191.0000 - val_loss: 0.0036 - val_precision: 0.9982 - val_recall: 0.9974 - val_tn: 194806.0000 - val_tp: 104730.0000\n",
      "Epoch 189/500\n",
      "147/147 - 2s - 12ms/step - fn: 136.0000 - fp: 155.0000 - loss: 162.1051 - precision: 0.9985 - recall: 0.9987 - tn: 195116.0000 - tp: 104593.0000 - val_fn: 301.0000 - val_fp: 189.0000 - val_loss: 0.0037 - val_precision: 0.9982 - val_recall: 0.9971 - val_tn: 194808.0000 - val_tp: 104702.0000\n",
      "Epoch 190/500\n",
      "147/147 - 2s - 12ms/step - fn: 137.0000 - fp: 181.0000 - loss: 169.4722 - precision: 0.9983 - recall: 0.9987 - tn: 195090.0000 - tp: 104592.0000 - val_fn: 337.0000 - val_fp: 169.0000 - val_loss: 0.0038 - val_precision: 0.9984 - val_recall: 0.9968 - val_tn: 194828.0000 - val_tp: 104666.0000\n",
      "Epoch 191/500\n",
      "147/147 - 2s - 12ms/step - fn: 123.0000 - fp: 174.0000 - loss: 165.3329 - precision: 0.9983 - recall: 0.9988 - tn: 195097.0000 - tp: 104606.0000 - val_fn: 228.0000 - val_fp: 236.0000 - val_loss: 0.0036 - val_precision: 0.9978 - val_recall: 0.9978 - val_tn: 194761.0000 - val_tp: 104775.0000\n",
      "Epoch 192/500\n",
      "147/147 - 2s - 11ms/step - fn: 135.0000 - fp: 148.0000 - loss: 155.9258 - precision: 0.9986 - recall: 0.9987 - tn: 195123.0000 - tp: 104594.0000 - val_fn: 328.0000 - val_fp: 163.0000 - val_loss: 0.0039 - val_precision: 0.9984 - val_recall: 0.9969 - val_tn: 194834.0000 - val_tp: 104675.0000\n",
      "Epoch 193/500\n",
      "147/147 - 2s - 13ms/step - fn: 138.0000 - fp: 167.0000 - loss: 157.3923 - precision: 0.9984 - recall: 0.9987 - tn: 195104.0000 - tp: 104591.0000 - val_fn: 238.0000 - val_fp: 219.0000 - val_loss: 0.0036 - val_precision: 0.9979 - val_recall: 0.9977 - val_tn: 194778.0000 - val_tp: 104765.0000\n",
      "Epoch 194/500\n",
      "147/147 - 2s - 12ms/step - fn: 128.0000 - fp: 170.0000 - loss: 165.6682 - precision: 0.9984 - recall: 0.9988 - tn: 195101.0000 - tp: 104601.0000 - val_fn: 252.0000 - val_fp: 252.0000 - val_loss: 0.0039 - val_precision: 0.9976 - val_recall: 0.9976 - val_tn: 194745.0000 - val_tp: 104751.0000\n",
      "Epoch 195/500\n",
      "147/147 - 2s - 11ms/step - fn: 139.0000 - fp: 173.0000 - loss: 171.4611 - precision: 0.9983 - recall: 0.9987 - tn: 195098.0000 - tp: 104590.0000 - val_fn: 270.0000 - val_fp: 204.0000 - val_loss: 0.0037 - val_precision: 0.9981 - val_recall: 0.9974 - val_tn: 194793.0000 - val_tp: 104733.0000\n",
      "Epoch 196/500\n",
      "147/147 - 2s - 12ms/step - fn: 124.0000 - fp: 183.0000 - loss: 167.7436 - precision: 0.9983 - recall: 0.9988 - tn: 195088.0000 - tp: 104605.0000 - val_fn: 370.0000 - val_fp: 148.0000 - val_loss: 0.0040 - val_precision: 0.9986 - val_recall: 0.9965 - val_tn: 194849.0000 - val_tp: 104633.0000\n",
      "Epoch 197/500\n",
      "147/147 - 2s - 13ms/step - fn: 127.0000 - fp: 157.0000 - loss: 159.1930 - precision: 0.9985 - recall: 0.9988 - tn: 195114.0000 - tp: 104602.0000 - val_fn: 286.0000 - val_fp: 212.0000 - val_loss: 0.0038 - val_precision: 0.9980 - val_recall: 0.9973 - val_tn: 194785.0000 - val_tp: 104717.0000\n",
      "Epoch 198/500\n",
      "147/147 - 3s - 17ms/step - fn: 142.0000 - fp: 167.0000 - loss: 162.8848 - precision: 0.9984 - recall: 0.9986 - tn: 195104.0000 - tp: 104587.0000 - val_fn: 326.0000 - val_fp: 171.0000 - val_loss: 0.0040 - val_precision: 0.9984 - val_recall: 0.9969 - val_tn: 194826.0000 - val_tp: 104677.0000\n",
      "Epoch 199/500\n",
      "147/147 - 2s - 13ms/step - fn: 134.0000 - fp: 159.0000 - loss: 162.3872 - precision: 0.9985 - recall: 0.9987 - tn: 195112.0000 - tp: 104595.0000 - val_fn: 210.0000 - val_fp: 253.0000 - val_loss: 0.0036 - val_precision: 0.9976 - val_recall: 0.9980 - val_tn: 194744.0000 - val_tp: 104793.0000\n",
      "Epoch 200/500\n",
      "147/147 - 2s - 12ms/step - fn: 143.0000 - fp: 179.0000 - loss: 163.4317 - precision: 0.9983 - recall: 0.9986 - tn: 195092.0000 - tp: 104586.0000 - val_fn: 326.0000 - val_fp: 179.0000 - val_loss: 0.0040 - val_precision: 0.9983 - val_recall: 0.9969 - val_tn: 194818.0000 - val_tp: 104677.0000\n",
      "Epoch 201/500\n",
      "147/147 - 2s - 12ms/step - fn: 119.0000 - fp: 155.0000 - loss: 156.9958 - precision: 0.9985 - recall: 0.9989 - tn: 195116.0000 - tp: 104610.0000 - val_fn: 234.0000 - val_fp: 237.0000 - val_loss: 0.0038 - val_precision: 0.9977 - val_recall: 0.9978 - val_tn: 194760.0000 - val_tp: 104769.0000\n",
      "Epoch 202/500\n",
      "147/147 - 2s - 11ms/step - fn: 153.0000 - fp: 165.0000 - loss: 178.5711 - precision: 0.9984 - recall: 0.9985 - tn: 195106.0000 - tp: 104576.0000 - val_fn: 218.0000 - val_fp: 213.0000 - val_loss: 0.0034 - val_precision: 0.9980 - val_recall: 0.9979 - val_tn: 194784.0000 - val_tp: 104785.0000\n",
      "Epoch 203/500\n",
      "147/147 - 2s - 12ms/step - fn: 115.0000 - fp: 160.0000 - loss: 157.6469 - precision: 0.9985 - recall: 0.9989 - tn: 195111.0000 - tp: 104614.0000 - val_fn: 266.0000 - val_fp: 220.0000 - val_loss: 0.0038 - val_precision: 0.9979 - val_recall: 0.9975 - val_tn: 194777.0000 - val_tp: 104737.0000\n",
      "Epoch 204/500\n",
      "147/147 - 2s - 12ms/step - fn: 136.0000 - fp: 176.0000 - loss: 168.8680 - precision: 0.9983 - recall: 0.9987 - tn: 195095.0000 - tp: 104593.0000 - val_fn: 327.0000 - val_fp: 181.0000 - val_loss: 0.0039 - val_precision: 0.9983 - val_recall: 0.9969 - val_tn: 194816.0000 - val_tp: 104676.0000\n",
      "Epoch 205/500\n",
      "147/147 - 2s - 13ms/step - fn: 127.0000 - fp: 162.0000 - loss: 159.6035 - precision: 0.9985 - recall: 0.9988 - tn: 195109.0000 - tp: 104602.0000 - val_fn: 226.0000 - val_fp: 207.0000 - val_loss: 0.0034 - val_precision: 0.9980 - val_recall: 0.9978 - val_tn: 194790.0000 - val_tp: 104777.0000\n",
      "Epoch 206/500\n",
      "147/147 - 2s - 12ms/step - fn: 139.0000 - fp: 175.0000 - loss: 175.4144 - precision: 0.9983 - recall: 0.9987 - tn: 195096.0000 - tp: 104590.0000 - val_fn: 331.0000 - val_fp: 142.0000 - val_loss: 0.0036 - val_precision: 0.9986 - val_recall: 0.9968 - val_tn: 194855.0000 - val_tp: 104672.0000\n",
      "Epoch 207/500\n",
      "147/147 - 2s - 12ms/step - fn: 130.0000 - fp: 159.0000 - loss: 161.8003 - precision: 0.9985 - recall: 0.9988 - tn: 195112.0000 - tp: 104599.0000 - val_fn: 449.0000 - val_fp: 113.0000 - val_loss: 0.0046 - val_precision: 0.9989 - val_recall: 0.9957 - val_tn: 194884.0000 - val_tp: 104554.0000\n",
      "Epoch 208/500\n",
      "147/147 - 2s - 13ms/step - fn: 133.0000 - fp: 162.0000 - loss: 162.6856 - precision: 0.9985 - recall: 0.9987 - tn: 195109.0000 - tp: 104596.0000 - val_fn: 337.0000 - val_fp: 158.0000 - val_loss: 0.0039 - val_precision: 0.9985 - val_recall: 0.9968 - val_tn: 194839.0000 - val_tp: 104666.0000\n",
      "Epoch 209/500\n",
      "147/147 - 2s - 13ms/step - fn: 109.0000 - fp: 139.0000 - loss: 146.2545 - precision: 0.9987 - recall: 0.9990 - tn: 195132.0000 - tp: 104620.0000 - val_fn: 292.0000 - val_fp: 221.0000 - val_loss: 0.0039 - val_precision: 0.9979 - val_recall: 0.9972 - val_tn: 194776.0000 - val_tp: 104711.0000\n",
      "Epoch 210/500\n",
      "147/147 - 2s - 12ms/step - fn: 139.0000 - fp: 158.0000 - loss: 168.6245 - precision: 0.9985 - recall: 0.9987 - tn: 195113.0000 - tp: 104590.0000 - val_fn: 343.0000 - val_fp: 201.0000 - val_loss: 0.0043 - val_precision: 0.9981 - val_recall: 0.9967 - val_tn: 194796.0000 - val_tp: 104660.0000\n",
      "Epoch 211/500\n",
      "147/147 - 2s - 12ms/step - fn: 120.0000 - fp: 162.0000 - loss: 160.8384 - precision: 0.9985 - recall: 0.9989 - tn: 195109.0000 - tp: 104609.0000 - val_fn: 449.0000 - val_fp: 106.0000 - val_loss: 0.0045 - val_precision: 0.9990 - val_recall: 0.9957 - val_tn: 194891.0000 - val_tp: 104554.0000\n",
      "Epoch 212/500\n",
      "147/147 - 2s - 12ms/step - fn: 130.0000 - fp: 163.0000 - loss: 159.2420 - precision: 0.9984 - recall: 0.9988 - tn: 195108.0000 - tp: 104599.0000 - val_fn: 340.0000 - val_fp: 166.0000 - val_loss: 0.0041 - val_precision: 0.9984 - val_recall: 0.9968 - val_tn: 194831.0000 - val_tp: 104663.0000\n",
      "Epoch 213/500\n",
      "147/147 - 2s - 12ms/step - fn: 129.0000 - fp: 143.0000 - loss: 152.4386 - precision: 0.9986 - recall: 0.9988 - tn: 195128.0000 - tp: 104600.0000 - val_fn: 317.0000 - val_fp: 154.0000 - val_loss: 0.0038 - val_precision: 0.9985 - val_recall: 0.9970 - val_tn: 194843.0000 - val_tp: 104686.0000\n",
      "Epoch 214/500\n",
      "147/147 - 2s - 12ms/step - fn: 127.0000 - fp: 186.0000 - loss: 166.7104 - precision: 0.9982 - recall: 0.9988 - tn: 195085.0000 - tp: 104602.0000 - val_fn: 253.0000 - val_fp: 211.0000 - val_loss: 0.0036 - val_precision: 0.9980 - val_recall: 0.9976 - val_tn: 194786.0000 - val_tp: 104750.0000\n",
      "Epoch 215/500\n",
      "147/147 - 2s - 11ms/step - fn: 115.0000 - fp: 142.0000 - loss: 149.2819 - precision: 0.9986 - recall: 0.9989 - tn: 195129.0000 - tp: 104614.0000 - val_fn: 230.0000 - val_fp: 248.0000 - val_loss: 0.0038 - val_precision: 0.9976 - val_recall: 0.9978 - val_tn: 194749.0000 - val_tp: 104773.0000\n",
      "Epoch 216/500\n",
      "147/147 - 2s - 11ms/step - fn: 125.0000 - fp: 165.0000 - loss: 153.7296 - precision: 0.9984 - recall: 0.9988 - tn: 195106.0000 - tp: 104604.0000 - val_fn: 262.0000 - val_fp: 212.0000 - val_loss: 0.0037 - val_precision: 0.9980 - val_recall: 0.9975 - val_tn: 194785.0000 - val_tp: 104741.0000\n",
      "Epoch 217/500\n",
      "147/147 - 2s - 12ms/step - fn: 115.0000 - fp: 149.0000 - loss: 144.8790 - precision: 0.9986 - recall: 0.9989 - tn: 195122.0000 - tp: 104614.0000 - val_fn: 302.0000 - val_fp: 151.0000 - val_loss: 0.0036 - val_precision: 0.9986 - val_recall: 0.9971 - val_tn: 194846.0000 - val_tp: 104701.0000\n",
      "Epoch 218/500\n",
      "147/147 - 2s - 12ms/step - fn: 127.0000 - fp: 152.0000 - loss: 151.7982 - precision: 0.9985 - recall: 0.9988 - tn: 195119.0000 - tp: 104602.0000 - val_fn: 434.0000 - val_fp: 144.0000 - val_loss: 0.0048 - val_precision: 0.9986 - val_recall: 0.9959 - val_tn: 194853.0000 - val_tp: 104569.0000\n",
      "Epoch 219/500\n",
      "147/147 - 2s - 11ms/step - fn: 143.0000 - fp: 172.0000 - loss: 169.4807 - precision: 0.9984 - recall: 0.9986 - tn: 195099.0000 - tp: 104586.0000 - val_fn: 247.0000 - val_fp: 210.0000 - val_loss: 0.0036 - val_precision: 0.9980 - val_recall: 0.9976 - val_tn: 194787.0000 - val_tp: 104756.0000\n",
      "Epoch 220/500\n",
      "147/147 - 2s - 12ms/step - fn: 128.0000 - fp: 156.0000 - loss: 159.8002 - precision: 0.9985 - recall: 0.9988 - tn: 195115.0000 - tp: 104601.0000 - val_fn: 255.0000 - val_fp: 212.0000 - val_loss: 0.0037 - val_precision: 0.9980 - val_recall: 0.9976 - val_tn: 194785.0000 - val_tp: 104748.0000\n",
      "Epoch 221/500\n",
      "147/147 - 2s - 12ms/step - fn: 136.0000 - fp: 149.0000 - loss: 154.2782 - precision: 0.9986 - recall: 0.9987 - tn: 195122.0000 - tp: 104593.0000 - val_fn: 231.0000 - val_fp: 225.0000 - val_loss: 0.0035 - val_precision: 0.9979 - val_recall: 0.9978 - val_tn: 194772.0000 - val_tp: 104772.0000\n",
      "Epoch 222/500\n",
      "147/147 - 2s - 11ms/step - fn: 110.0000 - fp: 140.0000 - loss: 146.3908 - precision: 0.9987 - recall: 0.9989 - tn: 195131.0000 - tp: 104619.0000 - val_fn: 312.0000 - val_fp: 167.0000 - val_loss: 0.0036 - val_precision: 0.9984 - val_recall: 0.9970 - val_tn: 194830.0000 - val_tp: 104691.0000\n",
      "Epoch 223/500\n",
      "147/147 - 2s - 10ms/step - fn: 108.0000 - fp: 139.0000 - loss: 145.0044 - precision: 0.9987 - recall: 0.9990 - tn: 195132.0000 - tp: 104621.0000 - val_fn: 360.0000 - val_fp: 155.0000 - val_loss: 0.0041 - val_precision: 0.9985 - val_recall: 0.9966 - val_tn: 194842.0000 - val_tp: 104643.0000\n",
      "Epoch 224/500\n",
      "147/147 - 2s - 12ms/step - fn: 121.0000 - fp: 164.0000 - loss: 153.4570 - precision: 0.9984 - recall: 0.9988 - tn: 195107.0000 - tp: 104608.0000 - val_fn: 370.0000 - val_fp: 121.0000 - val_loss: 0.0038 - val_precision: 0.9988 - val_recall: 0.9965 - val_tn: 194876.0000 - val_tp: 104633.0000\n",
      "Epoch 225/500\n",
      "147/147 - 2s - 12ms/step - fn: 107.0000 - fp: 131.0000 - loss: 133.8461 - precision: 0.9987 - recall: 0.9990 - tn: 195140.0000 - tp: 104622.0000 - val_fn: 282.0000 - val_fp: 178.0000 - val_loss: 0.0036 - val_precision: 0.9983 - val_recall: 0.9973 - val_tn: 194819.0000 - val_tp: 104721.0000\n",
      "Epoch 226/500\n",
      "147/147 - 2s - 12ms/step - fn: 123.0000 - fp: 145.0000 - loss: 150.7951 - precision: 0.9986 - recall: 0.9988 - tn: 195126.0000 - tp: 104606.0000 - val_fn: 385.0000 - val_fp: 121.0000 - val_loss: 0.0040 - val_precision: 0.9988 - val_recall: 0.9963 - val_tn: 194876.0000 - val_tp: 104618.0000\n",
      "Epoch 227/500\n",
      "147/147 - 2s - 12ms/step - fn: 119.0000 - fp: 146.0000 - loss: 146.2399 - precision: 0.9986 - recall: 0.9989 - tn: 195125.0000 - tp: 104610.0000 - val_fn: 342.0000 - val_fp: 125.0000 - val_loss: 0.0036 - val_precision: 0.9988 - val_recall: 0.9967 - val_tn: 194872.0000 - val_tp: 104661.0000\n",
      "Epoch 228/500\n",
      "147/147 - 2s - 11ms/step - fn: 128.0000 - fp: 147.0000 - loss: 149.2851 - precision: 0.9986 - recall: 0.9988 - tn: 195124.0000 - tp: 104601.0000 - val_fn: 337.0000 - val_fp: 161.0000 - val_loss: 0.0042 - val_precision: 0.9985 - val_recall: 0.9968 - val_tn: 194836.0000 - val_tp: 104666.0000\n",
      "Epoch 229/500\n",
      "147/147 - 2s - 11ms/step - fn: 114.0000 - fp: 155.0000 - loss: 150.8008 - precision: 0.9985 - recall: 0.9989 - tn: 195116.0000 - tp: 104615.0000 - val_fn: 246.0000 - val_fp: 227.0000 - val_loss: 0.0038 - val_precision: 0.9978 - val_recall: 0.9977 - val_tn: 194770.0000 - val_tp: 104757.0000\n",
      "Epoch 230/500\n",
      "147/147 - 2s - 11ms/step - fn: 108.0000 - fp: 135.0000 - loss: 143.4517 - precision: 0.9987 - recall: 0.9990 - tn: 195136.0000 - tp: 104621.0000 - val_fn: 281.0000 - val_fp: 176.0000 - val_loss: 0.0035 - val_precision: 0.9983 - val_recall: 0.9973 - val_tn: 194821.0000 - val_tp: 104722.0000\n",
      "Epoch 231/500\n",
      "147/147 - 2s - 11ms/step - fn: 111.0000 - fp: 147.0000 - loss: 148.7363 - precision: 0.9986 - recall: 0.9989 - tn: 195124.0000 - tp: 104618.0000 - val_fn: 240.0000 - val_fp: 201.0000 - val_loss: 0.0034 - val_precision: 0.9981 - val_recall: 0.9977 - val_tn: 194796.0000 - val_tp: 104763.0000\n",
      "Epoch 232/500\n",
      "147/147 - 2s - 11ms/step - fn: 111.0000 - fp: 137.0000 - loss: 143.3057 - precision: 0.9987 - recall: 0.9989 - tn: 195134.0000 - tp: 104618.0000 - val_fn: 232.0000 - val_fp: 186.0000 - val_loss: 0.0033 - val_precision: 0.9982 - val_recall: 0.9978 - val_tn: 194811.0000 - val_tp: 104771.0000\n",
      "Epoch 233/500\n",
      "147/147 - 2s - 11ms/step - fn: 112.0000 - fp: 149.0000 - loss: 141.2177 - precision: 0.9986 - recall: 0.9989 - tn: 195122.0000 - tp: 104617.0000 - val_fn: 344.0000 - val_fp: 170.0000 - val_loss: 0.0042 - val_precision: 0.9984 - val_recall: 0.9967 - val_tn: 194827.0000 - val_tp: 104659.0000\n",
      "Epoch 234/500\n",
      "147/147 - 2s - 11ms/step - fn: 132.0000 - fp: 166.0000 - loss: 149.3098 - precision: 0.9984 - recall: 0.9987 - tn: 195105.0000 - tp: 104597.0000 - val_fn: 376.0000 - val_fp: 133.0000 - val_loss: 0.0043 - val_precision: 0.9987 - val_recall: 0.9964 - val_tn: 194864.0000 - val_tp: 104627.0000\n",
      "Epoch 235/500\n",
      "147/147 - 2s - 11ms/step - fn: 117.0000 - fp: 151.0000 - loss: 146.3920 - precision: 0.9986 - recall: 0.9989 - tn: 195120.0000 - tp: 104612.0000 - val_fn: 237.0000 - val_fp: 211.0000 - val_loss: 0.0036 - val_precision: 0.9980 - val_recall: 0.9977 - val_tn: 194786.0000 - val_tp: 104766.0000\n",
      "Epoch 236/500\n",
      "147/147 - 2s - 12ms/step - fn: 122.0000 - fp: 141.0000 - loss: 144.4376 - precision: 0.9987 - recall: 0.9988 - tn: 195130.0000 - tp: 104607.0000 - val_fn: 210.0000 - val_fp: 270.0000 - val_loss: 0.0039 - val_precision: 0.9974 - val_recall: 0.9980 - val_tn: 194727.0000 - val_tp: 104793.0000\n",
      "Epoch 237/500\n",
      "147/147 - 2s - 11ms/step - fn: 131.0000 - fp: 153.0000 - loss: 148.6036 - precision: 0.9985 - recall: 0.9987 - tn: 195118.0000 - tp: 104598.0000 - val_fn: 329.0000 - val_fp: 147.0000 - val_loss: 0.0039 - val_precision: 0.9986 - val_recall: 0.9969 - val_tn: 194850.0000 - val_tp: 104674.0000\n",
      "Epoch 238/500\n",
      "147/147 - 2s - 10ms/step - fn: 114.0000 - fp: 135.0000 - loss: 141.9566 - precision: 0.9987 - recall: 0.9989 - tn: 195136.0000 - tp: 104615.0000 - val_fn: 300.0000 - val_fp: 230.0000 - val_loss: 0.0044 - val_precision: 0.9978 - val_recall: 0.9971 - val_tn: 194767.0000 - val_tp: 104703.0000\n",
      "Epoch 239/500\n",
      "147/147 - 2s - 11ms/step - fn: 131.0000 - fp: 135.0000 - loss: 139.5020 - precision: 0.9987 - recall: 0.9987 - tn: 195136.0000 - tp: 104598.0000 - val_fn: 193.0000 - val_fp: 247.0000 - val_loss: 0.0034 - val_precision: 0.9976 - val_recall: 0.9982 - val_tn: 194750.0000 - val_tp: 104810.0000\n",
      "Epoch 240/500\n",
      "147/147 - 2s - 11ms/step - fn: 100.0000 - fp: 141.0000 - loss: 136.2945 - precision: 0.9987 - recall: 0.9990 - tn: 195130.0000 - tp: 104629.0000 - val_fn: 255.0000 - val_fp: 205.0000 - val_loss: 0.0036 - val_precision: 0.9980 - val_recall: 0.9976 - val_tn: 194792.0000 - val_tp: 104748.0000\n",
      "Epoch 241/500\n",
      "147/147 - 2s - 11ms/step - fn: 116.0000 - fp: 150.0000 - loss: 141.5183 - precision: 0.9986 - recall: 0.9989 - tn: 195121.0000 - tp: 104613.0000 - val_fn: 337.0000 - val_fp: 174.0000 - val_loss: 0.0041 - val_precision: 0.9983 - val_recall: 0.9968 - val_tn: 194823.0000 - val_tp: 104666.0000\n",
      "Epoch 242/500\n",
      "147/147 - 2s - 11ms/step - fn: 115.0000 - fp: 134.0000 - loss: 142.4080 - precision: 0.9987 - recall: 0.9989 - tn: 195137.0000 - tp: 104614.0000 - val_fn: 217.0000 - val_fp: 238.0000 - val_loss: 0.0038 - val_precision: 0.9977 - val_recall: 0.9979 - val_tn: 194759.0000 - val_tp: 104786.0000\n",
      "Epoch 243/500\n",
      "147/147 - 2s - 11ms/step - fn: 129.0000 - fp: 164.0000 - loss: 150.8969 - precision: 0.9984 - recall: 0.9988 - tn: 195107.0000 - tp: 104600.0000 - val_fn: 376.0000 - val_fp: 177.0000 - val_loss: 0.0046 - val_precision: 0.9983 - val_recall: 0.9964 - val_tn: 194820.0000 - val_tp: 104627.0000\n",
      "Epoch 244/500\n",
      "147/147 - 2s - 11ms/step - fn: 122.0000 - fp: 155.0000 - loss: 155.9802 - precision: 0.9985 - recall: 0.9988 - tn: 195116.0000 - tp: 104607.0000 - val_fn: 285.0000 - val_fp: 154.0000 - val_loss: 0.0036 - val_precision: 0.9985 - val_recall: 0.9973 - val_tn: 194843.0000 - val_tp: 104718.0000\n",
      "Epoch 245/500\n",
      "147/147 - 2s - 11ms/step - fn: 121.0000 - fp: 154.0000 - loss: 140.9194 - precision: 0.9985 - recall: 0.9988 - tn: 195117.0000 - tp: 104608.0000 - val_fn: 442.0000 - val_fp: 122.0000 - val_loss: 0.0048 - val_precision: 0.9988 - val_recall: 0.9958 - val_tn: 194875.0000 - val_tp: 104561.0000\n",
      "Epoch 246/500\n",
      "147/147 - 2s - 11ms/step - fn: 109.0000 - fp: 133.0000 - loss: 139.5121 - precision: 0.9987 - recall: 0.9990 - tn: 195138.0000 - tp: 104620.0000 - val_fn: 340.0000 - val_fp: 175.0000 - val_loss: 0.0041 - val_precision: 0.9983 - val_recall: 0.9968 - val_tn: 194822.0000 - val_tp: 104663.0000\n",
      "Epoch 247/500\n",
      "147/147 - 2s - 11ms/step - fn: 132.0000 - fp: 153.0000 - loss: 155.0397 - precision: 0.9985 - recall: 0.9987 - tn: 195118.0000 - tp: 104597.0000 - val_fn: 387.0000 - val_fp: 223.0000 - val_loss: 0.0055 - val_precision: 0.9979 - val_recall: 0.9963 - val_tn: 194774.0000 - val_tp: 104616.0000\n",
      "Epoch 248/500\n",
      "147/147 - 2s - 11ms/step - fn: 123.0000 - fp: 156.0000 - loss: 146.2788 - precision: 0.9985 - recall: 0.9988 - tn: 195115.0000 - tp: 104606.0000 - val_fn: 318.0000 - val_fp: 160.0000 - val_loss: 0.0038 - val_precision: 0.9985 - val_recall: 0.9970 - val_tn: 194837.0000 - val_tp: 104685.0000\n",
      "Epoch 249/500\n",
      "147/147 - 2s - 11ms/step - fn: 131.0000 - fp: 150.0000 - loss: 156.3960 - precision: 0.9986 - recall: 0.9987 - tn: 195121.0000 - tp: 104598.0000 - val_fn: 280.0000 - val_fp: 206.0000 - val_loss: 0.0039 - val_precision: 0.9980 - val_recall: 0.9973 - val_tn: 194791.0000 - val_tp: 104723.0000\n",
      "Epoch 250/500\n",
      "147/147 - 2s - 11ms/step - fn: 104.0000 - fp: 132.0000 - loss: 138.5170 - precision: 0.9987 - recall: 0.9990 - tn: 195139.0000 - tp: 104625.0000 - val_fn: 245.0000 - val_fp: 245.0000 - val_loss: 0.0038 - val_precision: 0.9977 - val_recall: 0.9977 - val_tn: 194752.0000 - val_tp: 104758.0000\n",
      "Epoch 250: early stopping\n",
      "Restoring model weights from the end of the best epoch: 225.\n",
      "9375/9375 - 8s - 906us/step - fn: 303.0000 - fp: 161.0000 - loss: 0.0039 - precision: 0.9985 - recall: 0.9971 - tn: 194665.0000 - tp: 104871.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0038521611131727695,\n",
       " 303.0,\n",
       " 161.0,\n",
       " 0.9984671473503113,\n",
       " 0.9971190690994263,\n",
       " 194665.0,\n",
       " 104871.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = network.fit_model(epochs=500, verbose=2)\n",
    "network.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network.model.save(\"chugunov_indicator/keras/model.keras\")\n",
    "network.model = keras.saving.load_model(\"chugunov_indicator/keras/model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei = pyna.Nucleus.cast_list([\"h1\", \"he4\", \"c12\", \"o16\", \"n14\", \"ca40\"])\n",
    "reactants = pyna.Nucleus.cast_list([\"c12\", \"he4\"])\n",
    "\n",
    "comp = pyna.Composition(nuclei=nuclei)\n",
    "comp.set_solar_like()\n",
    "\n",
    "scn_fac = pyna.make_screen_factors(*reactants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dens, temp = 1.e6, 2e8\n",
    "plasma = pyna.make_plasma_state(temp, dens, comp.get_molar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7457134746043816"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyna.screening.chugunov_2009(plasma, scn_fac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.predict_states(plasma, scn_fac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False negatives are mostly irrelevant, but false positives can cause significant errors to propagate through the system if not caught. Fortunately, an inspection of the false positives within the test data reveals that they all have screening factors within the interval $[1.01, 1.013]$, implying that the neural network is largely successful at its task.\n",
    "\n",
    "However, the `network.model.predict` method operates on the order of milliseconds, while an analysis `5. speed.ipynb` notebook reveals that a Python implementation of `chugunov_2009` itself operates on the order of microseconds. As such, a neural network like this is would not be effective for optimizing the runtime of `chugunov_2009`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9375/9375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 871us/step\n"
     ]
    }
   ],
   "source": [
    "fp = ((network.model.predict(test.inputs).squeeze() >= 0.5) & ~test.outputs) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.01001194, 1.01020107, 1.01000773, 1.01019415, 1.01000966,\n",
       "       1.01030038, 1.0103661 , 1.0104646 , 1.01054024, 1.01024759,\n",
       "       1.01068491, 1.01040766, 1.01085853, 1.01008068, 1.01079409,\n",
       "       1.01020378, 1.01002502, 1.01024663, 1.01000194, 1.0102119 ,\n",
       "       1.01004076, 1.0101782 , 1.01029973, 1.01016429, 1.0105595 ,\n",
       "       1.01005702, 1.01003274, 1.01213755, 1.01001769, 1.01009793,\n",
       "       1.01016006, 1.01057366, 1.01002678, 1.01044191, 1.01127694,\n",
       "       1.01010192, 1.01017348, 1.01089798, 1.01000898, 1.01031632,\n",
       "       1.01055381, 1.01056098, 1.01180212, 1.01005668, 1.01007959,\n",
       "       1.01050641, 1.01034203, 1.01013163, 1.01003947, 1.010122  ,\n",
       "       1.01065727, 1.01009619, 1.01025271, 1.01010378, 1.01081283,\n",
       "       1.01015662, 1.01000324, 1.01015354, 1.0110943 , 1.01010499,\n",
       "       1.01007202, 1.01000768, 1.01035353, 1.01020641, 1.01002173,\n",
       "       1.01026171, 1.01107069, 1.01095777, 1.01004197, 1.01022607,\n",
       "       1.01009426, 1.01099453, 1.010289  , 1.01051833, 1.01064581,\n",
       "       1.01048427, 1.01001739, 1.01014046, 1.01035738, 1.01005415,\n",
       "       1.01017987, 1.0101249 , 1.01028221, 1.01003272, 1.01058205,\n",
       "       1.01011865, 1.01020174, 1.01009709, 1.01058666, 1.01001846,\n",
       "       1.01015923, 1.01006505, 1.01001988, 1.01024445, 1.01037031,\n",
       "       1.0104513 , 1.01022526, 1.01136825, 1.01005427, 1.01007994,\n",
       "       1.01019614, 1.0100233 , 1.01007703, 1.01001561, 1.01018444,\n",
       "       1.01003013, 1.01062669, 1.0101743 , 1.01006474, 1.01035739,\n",
       "       1.0100413 , 1.01024825, 1.01039732, 1.01022021, 1.01047691,\n",
       "       1.01000161, 1.01296512, 1.01115017, 1.01137655, 1.01018335,\n",
       "       1.01112163, 1.0105816 , 1.01026433, 1.01006701, 1.0100249 ,\n",
       "       1.0110815 , 1.01011777, 1.01128902, 1.01023318, 1.01000868,\n",
       "       1.01004099, 1.01036022, 1.01029879, 1.01033885, 1.01016966,\n",
       "       1.01007317, 1.01010947, 1.01001159, 1.01007707, 1.01023317,\n",
       "       1.01011504, 1.01012155, 1.01005623, 1.01007461, 1.01032541,\n",
       "       1.01019315, 1.01006159, 1.01007978, 1.01000039, 1.0109241 ,\n",
       "       1.01004086, 1.01025578, 1.01006902, 1.01004355, 1.01000076,\n",
       "       1.01077302, 1.01057955, 1.01092312, 1.01030138, 1.01007399,\n",
       "       1.01086863])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0129651196810776"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    F_fp := test.F[fp == 1],\n",
    "    F_fp.size,\n",
    "    F_fp.max()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
